{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f025dc4c-2f86-483e-818e-2b3bd862b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skin_fusion\n",
    "\n",
    "import os, json, mimetypes\n",
    "import cv2, numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "TARGET_SHORT = 768\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "PROMPT_TEXT = (\n",
    "    \"전처리된 얼굴 피부 이미지를 분석하여 JSON만 반환하라.\\n\"\n",
    "    \"평가 항목: acne(여드름), redness(홍조), melasma_darkspots(잡티).\\n\"\n",
    "    \"각 항목은 다음 스키마로 제공하라:\\n\"\n",
    "    \"{acne:{score:number,reason:string}, redness:{score:number,reason:string}, \"\n",
    "    \"melasma_darkspots:{score:number,reason:string}}\\n\"\n",
    "    \"score는 0~100 범위의 실수.\"\n",
    ")\n",
    "\n",
    "def _load_exif_bgr(path: str):\n",
    "    pil = Image.open(path)\n",
    "    pil = ImageOps.exif_transpose(pil).convert(\"RGB\")\n",
    "    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def _resize_short(bgr, short=TARGET_SHORT):\n",
    "    h, w = bgr.shape[:2]\n",
    "    s = min(h, w)\n",
    "    if s == short: return bgr\n",
    "    scale = short / float(s)\n",
    "    new = (int(round(w * scale)), int(round(h * scale)))\n",
    "    interp = cv2.INTER_AREA if scale < 1 else cv2.INTER_CUBIC\n",
    "    return cv2.resize(bgr, new, interpolation=interp)\n",
    "\n",
    "def _wb_grayworld(bgr, strength=0.5):\n",
    "    x = bgr.astype(np.float32)\n",
    "    means = x.reshape(-1,3).mean(0) + 1e-6\n",
    "    g = means.mean()\n",
    "    gains = np.clip(g/means, 0.8, 1.2)\n",
    "    gains = (1-strength) + strength*gains\n",
    "    return np.clip(x*gains, 0, 255).astype(np.uint8)\n",
    "\n",
    "def _clahe_light(bgr, clip=1.8, tiles=8):\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    l,a,b = cv2.split(lab)\n",
    "    l = cv2.createCLAHE(clipLimit=clip, tileGridSize=(tiles, tiles)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def _morph_kernel(bgr, base=768, ksize=5):\n",
    "    h, w = bgr.shape[:2]\n",
    "    scale = min(h, w) / base\n",
    "    k = max(3, int(round(ksize * scale)))\n",
    "    if k % 2 == 0: k += 1\n",
    "    return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))\n",
    "\n",
    "def _skin_mask(bgr):\n",
    "    ycrcb = cv2.cvtColor(bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    Y, Cr, Cb = cv2.split(ycrcb)\n",
    "    m1 = (Cr>=135)&(Cr<=180)&(Cb>=85)&(Cb<=135)&(Y>=40)&(Y<=240)\n",
    "\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    H,S,V = cv2.split(hsv)\n",
    "    m2 = (H<=25)&(S>=30)&(S<=180)&(V>=60)\n",
    "\n",
    "    m = (m1 & m2).astype(np.uint8) * 255\n",
    "    k = _morph_kernel(bgr)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, k)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, k)\n",
    "\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(m)\n",
    "    if num > 1:\n",
    "        largest = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "        m = (labels == largest).astype(np.uint8) * 255\n",
    "    return m\n",
    "\n",
    "def preprocess_with_mask(bgr, bg_gray=220):\n",
    "    bgr = _resize_short(bgr)\n",
    "    bgr = _wb_grayworld(bgr)\n",
    "    bgr = _clahe_light(bgr)\n",
    "    mask = _skin_mask(bgr)\n",
    "    bg = np.full_like(bgr, bg_gray, np.uint8)\n",
    "    return np.where(mask[...,None]==255, bgr, bg)\n",
    "\n",
    "def analyze_with_gemini(image_path, api_key):\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    mime = mimetypes.guess_type(image_path)[0] or \"image/jpeg\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    content = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=PROMPT_TEXT),\n",
    "               types.Part(inline_data=types.Blob(mime_type=mime, data=data))]\n",
    "    )\n",
    "    resp = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[content],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            temperature=0.2,\n",
    "            system_instruction=\"반드시 JSON만 반환\"\n",
    "        )\n",
    "    )\n",
    "    txt = (resp.text or \"\").strip()\n",
    "    s, e = txt.find(\"{\"), txt.rfind(\"}\")\n",
    "    return json.loads(txt[s:e+1]) if s != -1 else {}\n",
    "\n",
    "MAP = {\n",
    "    \"q1\":{\"없어요\":0,\"T존 일부(이마 혹은 코)\":1,\"T존 전체(이마와 코)\":2,\"얼굴 전체\":3},\n",
    "    \"q2\":{\"전혀 안 보여요\":0,\"지금은 없지만 가끔 보여요\":1,\"부분적으로 붉게 보여요\":2,\"전체적으로 붉게 보여요\":3},\n",
    "    \"q3\":{\"없어요\":0,\"U존 일부(볼 혹은 턱)\":1,\"U존 전체(볼과 턱)\":2,\"얼굴 전체\":3},\n",
    "    \"q4\":{\"전혀 생기지 않아요\":0,\"표정을 지을 때만 생겨요\":1,\"표정 짓지 않아도 약간 있어요\":2,\"표정 짓지 않아도 많이 있어요\":3},\n",
    "    \"q5\":{\"주름이 없어요\":0,\"잔주름이에요\":1,\"깊은 주름이에요\":2,\"잔주름과 깊은 주름 다 있어요\":3},\n",
    "    \"q6\":{\"전혀 생기지 않아요\":0,\"미소 지을 때만 약간 생겨요\":1,\"미소 지을 때 진하게 생겨요\":2,\"미소 짓지 않아도 생겨요\":3},\n",
    "    \"q7\":{\"전혀 안 보여요\":0,\"거의 안 보여요\":1,\"약간 눈에 띄어요\":2,\"곳곳에 많이 보여요\":3},\n",
    "    \"q8\":{\"주름이 없어요\":0,\"잔주름이에요\":1,\"깊은 주름이에요\":2,\"잔주름과 깊은 주름 다 있어요\":3},\n",
    "    \"q9\":{\"외출 전보다 윤기가 없어요\":0,\"외출 전과 변함이 없어요\":1,\"약간 번들거리고 윤기가 있어요\":2,\"많이 번들거리고 기름져요\":3},\n",
    "    \"q10\":{\"전혀 안 보여요\":0,\"가끔 붉어지면 보여요\":1,\"특정부위에 눈에 띄어요\":2,\"곳곳에 많이 보여요\":3},\n",
    "}\n",
    "\n",
    "def _to_0_3(x):\n",
    "    v = float(x) if x else 0.0\n",
    "    return round(max(0,min(100,v))/100*3,2)\n",
    "\n",
    "def _skin_type(oil, dry):\n",
    "    if oil>=2 and dry<=1: return \"지성\"\n",
    "    if dry>=2 and oil<=1: return \"건성\"\n",
    "    if oil>=2 and dry>=2: return \"복합성\"\n",
    "    return \"중성\"\n",
    "\n",
    "def assess_skin_type(s):\n",
    "    sc = {k:MAP[k].get(v,0) for k,v in s.items()}\n",
    "    oil = round(0.6*sc[\"q1\"] + 0.4*sc[\"q9\"],2)\n",
    "    dry = float(sc[\"q3\"])\n",
    "    sens = round(0.7*sc[\"q2\"] + 0.3*sc[\"q10\"],2)\n",
    "    wrinkle = round(0.4*sc[\"q4\"] + 0.6*((sc[\"q5\"]+sc[\"q8\"])/2),2)\n",
    "    pigment = float(sc[\"q7\"])\n",
    "    return {\n",
    "        \"skin_type\": _skin_type(oil,dry),\n",
    "        \"indices\": {\"oil\":oil,\"dry\":dry,\"sensitivity\":sens,\"wrinkle\":wrinkle,\"pigment\":pigment}\n",
    "    }\n",
    "\n",
    "def assess_with_gemini(survey, gemini):\n",
    "    base = assess_skin_type(survey[\"survey\"])\n",
    "    idx = base[\"indices\"]\n",
    "    fused = idx.copy()\n",
    "\n",
    "    fused[\"sensitivity\"] = round(0.4*idx[\"sensitivity\"]+0.6*_to_0_3(gemini.get(\"redness\",{}).get(\"score\",0)),2)\n",
    "    fused[\"oil\"] = round(0.7*idx[\"oil\"]+0.3*_to_0_3(gemini.get(\"acne\",{}).get(\"score\",0)),2)\n",
    "    fused[\"pigment\"] = round(0.3*idx[\"pigment\"]+0.7*_to_0_3(gemini.get(\"melasma_darkspots\",{}).get(\"score\",0)),2)\n",
    "\n",
    "    return {\n",
    "        \"skin_type\": _skin_type(fused[\"oil\"], fused[\"dry\"]),\n",
    "        \"indices\": fused,\n",
    "        \"vision_raw\": gemini\n",
    "    }\n",
    "\n",
    "def run_fusion_from_request(image_path, survey_dict):\n",
    "    original = _load_exif_bgr(image_path)\n",
    "    processed = preprocess_with_mask(original)\n",
    "\n",
    "    root, ext = os.path.splitext(image_path)\n",
    "    if not ext: ext=\".jpg\"\n",
    "    pre_path = f\"{root}_Pre{ext}\"\n",
    "    cv2.imwrite(pre_path, processed)\n",
    "\n",
    "    gemini = analyze_with_gemini(pre_path, os.getenv(\"GEMINI_API_KEY\"))\n",
    "    return assess_with_gemini(survey_dict, gemini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da7c296-d2dc-4595-8ed6-8e983e998a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_ltr_online\n",
    "\n",
    "import os, json, math\n",
    "from typing import Dict, List\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import xgboost as xgb\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\", request_timeout=20)\n",
    "\n",
    "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "CATEGORIES = [\"cream\", \"essence\", \"skintoner\"]\n",
    "\n",
    "POS_ING = {\n",
    "    \"pigment\":{\"niacinamide\",\"비타민c\",\"arbutin\",\"트라넥삼산\",\"감초\",\"코직\"},\n",
    "    \"sensitivity\":{\"panthenol\",\"판테놀\",\"cica\",\"병풀\",\"알란토인\",\"베타글루칸\",\"알로에\",\"세라마이드\"},\n",
    "    \"dry\":{\"히알루론산\",\"글리세린\",\"스쿠알란\",\"세라마이드\",\"콜레스테롤\",\"요소\"},\n",
    "    \"acne\":{\"살리실산\",\"바하\",\"아젤라익\",\"아연\"},\n",
    "}\n",
    "NEG_ING = {\n",
    "    \"sensitivity\":{\"향\",\"향료\",\"퍼퓸\",\"알코올\",\"에탄올\",\"에센셜 오일\",\"티트리 오일\"},\n",
    "    \"acne\":{\"코코넛 오일\",\"아이소프로필 미리스테이트\",\"라놀린\"}\n",
    "}\n",
    "\n",
    "def _make_pos_neg_vocab(fusion):\n",
    "    idx = fusion[\"indices\"]\n",
    "    pos, neg = set(), set()\n",
    "    if idx[\"pigment\"]>=2: pos |= POS_ING[\"pigment\"]\n",
    "    if idx[\"sensitivity\"]>=2: pos |= POS_ING[\"sensitivity\"]; neg |= NEG_ING[\"sensitivity\"]\n",
    "    if idx[\"dry\"]>=2: pos |= POS_ING[\"dry\"]\n",
    "    if idx[\"oil\"]>=2: pos |= POS_ING[\"acne\"]; neg |= NEG_ING[\"acne\"]\n",
    "    return pos, neg\n",
    "\n",
    "def _cosine(a,b): \n",
    "    return float((a @ b) / (np.linalg.norm(a)*np.linalg.norm(b) + 1e-6))\n",
    "\n",
    "def search_candidates(es, fusion, per_cat=20):\n",
    "    qtext = fusion[\"skin_type\"]\n",
    "    qvec = model.encode(qtext).tolist()\n",
    "    out = {}\n",
    "    for cat in CATEGORIES:\n",
    "        body = {\n",
    "            \"size\":per_cat,\n",
    "            \"query\":{\n",
    "                \"bool\":{\n",
    "                    \"filter\":[{\"term\":{\"category\":cat}}],\n",
    "                    \"must\":[\n",
    "                        {\n",
    "                            \"script_score\":{\n",
    "                                \"query\":{\"match_all\":{}},\n",
    "                                \"script\":{\"source\":\"cosineSimilarity(params.qvec, 'review_vector') + 1.0\",\n",
    "                                          \"params\":{\"qvec\":qvec}}\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"_source\":[\"product_id\",\"productName\",\"brand\",\"salePrice\",\n",
    "                       \"ingredients\",\"averageReviewScore\",\"totalReviewCount\"]\n",
    "        }\n",
    "        hits = es.search(index=\"cosmetics_demo\", body=body)[\"hits\"][\"hits\"]\n",
    "        out[cat] = [{**h[\"_source\"], \"score_es\":h[\"_score\"]} for h in hits]\n",
    "    return out\n",
    "\n",
    "def featurize(results, fusion):\n",
    "    pos, neg = _make_pos_neg_vocab(fusion)\n",
    "    X, group, info = [], [], []\n",
    "\n",
    "    for cat in CATEGORIES:\n",
    "        rows = results.get(cat, [])\n",
    "        group.append(len(rows))\n",
    "        for r in rows:\n",
    "            ings = r.get(\"ingredients\", [])\n",
    "            pos_hits = sum(1 for x in ings if x in pos)\n",
    "            neg_hits = sum(1 for x in ings if x in neg)\n",
    "            avg = r.get(\"averageReviewScore\") or 0.0\n",
    "            cnt = math.log1p(r.get(\"totalReviewCount\") or 0.0)\n",
    "            price = math.log1p(r.get(\"salePrice\") or 0.0)\n",
    "            X.append([pos_hits, neg_hits, pos_hits-neg_hits, avg, cnt, price, r[\"score_es\"]])\n",
    "            info.append(r)\n",
    "    return X, group, info\n",
    "\n",
    "def recommend_for_request(fusion_json: dict, topk=3):\n",
    "    raw = search_candidates(es, fusion_json, per_cat=20)\n",
    "    X, groups, info = featurize(raw, fusion_json)\n",
    "\n",
    "    dtest = xgb.DMatrix(X)\n",
    "    preds = booster.predict(dtest)\n",
    "\n",
    "    ranked = []\n",
    "    for r,p in zip(info, preds):\n",
    "        r = dict(r)\n",
    "        r[\"score_ltr\"] = float(p)\n",
    "        ranked.append(r)\n",
    "\n",
    "    ranked.sort(key=lambda x: x[\"score_ltr\"], reverse=True)\n",
    "    return ranked[:topk]\n",
    "\n",
    "booster = xgb.Booster()\n",
    "booster.load_model(\"ltr_booster.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955925f4-a6da-4033-af9e-7bf3b1e76301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#offline_setup\n",
    "\n",
    "import os, json, hashlib, re\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import xgboost as xgb\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\", request_timeout=20)\n",
    "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize(doc, category):\n",
    "    name = doc.get(\"productName\",\"\")\n",
    "    brand = doc.get(\"mallName\",\"\")\n",
    "    pid = hashlib.md5(f\"{name}|{brand}\".encode()).hexdigest()\n",
    "\n",
    "    reviews = doc.get(\"reviews\") or []\n",
    "    text = \" \".join([r.get(\"reviewContent\",\"\") for r in reviews])[:5000]\n",
    "    vec = model.encode(text).tolist()\n",
    "\n",
    "    return {\n",
    "        \"product_id\":pid,\n",
    "        \"productName\":name,\n",
    "        \"brand\":brand,\n",
    "        \"category\":category,\n",
    "        \"ingredients\":doc.get(\"ingredients\",[]),\n",
    "        \"salePrice\":doc.get(\"salePrice\"),\n",
    "        \"averageReviewScore\":doc.get(\"averageReviewScore\"),\n",
    "        \"totalReviewCount\":doc.get(\"totalReviewCount\"),\n",
    "        \"review_vector\":vec\n",
    "    }\n",
    "\n",
    "def index_all():\n",
    "    docs=[]\n",
    "    for fname,cat in [(\"cream.json\",\"cream\"),(\"essence.json\",\"essence\"),(\"skintoner.json\",\"skintoner\")]:\n",
    "        if os.path.exists(fname):\n",
    "            for d in load_json(fname):\n",
    "                docs.append(normalize(d,cat))\n",
    "\n",
    "    ops = ({\"_op_type\":\"index\",\"_index\":\"cosmetics_demo\",\"_id\":d[\"product_id\"],\"_source\":d} for d in docs)\n",
    "    helpers.bulk(es, ops)\n",
    "\n",
    "def train_ltr():\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    index_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c6ffc-4820-41a6-86a3-c24e1d7fecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, hashlib, re\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import xgboost as xgb\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\", request_timeout=20)\n",
    "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize(doc, category):\n",
    "    name = doc.get(\"productName\",\"\")\n",
    "    brand = doc.get(\"mallName\",\"\")\n",
    "    pid = hashlib.md5(f\"{name}|{brand}\".encode()).hexdigest()\n",
    "\n",
    "    reviews = doc.get(\"reviews\") or []\n",
    "    text = \" \".join([r.get(\"reviewContent\",\"\") for r in reviews])[:5000]\n",
    "    vec = model.encode(text).tolist()\n",
    "\n",
    "    return {\n",
    "        \"product_id\":pid,\n",
    "        \"productName\":name,\n",
    "        \"brand\":brand,\n",
    "        \"category\":category,\n",
    "        \"ingredients\":doc.get(\"ingredients\",[]),\n",
    "        \"salePrice\":doc.get(\"salePrice\"),\n",
    "        \"averageReviewScore\":doc.get(\"averageReviewScore\"),\n",
    "        \"totalReviewCount\":doc.get(\"totalReviewCount\"),\n",
    "        \"review_vector\":vec\n",
    "    }\n",
    "\n",
    "def index_all():\n",
    "    docs=[]\n",
    "    for fname,cat in [(\"cream.json\",\"cream\"),(\"essence.json\",\"essence\"),(\"skintoner.json\",\"skintoner\")]:\n",
    "        if os.path.exists(fname):\n",
    "            for d in load_json(fname):\n",
    "                docs.append(normalize(d,cat))\n",
    "\n",
    "    ops = ({\"_op_type\":\"index\",\"_index\":\"cosmetics_demo\",\"_id\":d[\"product_id\"],\"_source\":d} for d in docs)\n",
    "    helpers.bulk(es, ops)\n",
    "\n",
    "def train_ltr():\n",
    "    pass  # (여기엔 X, y, group → XGBoost rank:ndcg 학습 코드가 들어감)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    index_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
