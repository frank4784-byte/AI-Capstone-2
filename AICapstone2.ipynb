{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ebda487-a45a-416c-ab97-b753397f261f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 전처리 완료: Lee_Pre.jpg\n",
      "\n",
      "[설문+이미지 융합 결과]\n",
      "{\n",
      "  \"skin_type\": \"중성\",\n",
      "  \"indices\": {\n",
      "    \"oil\": 1.53,\n",
      "    \"dry\": 1.0,\n",
      "    \"sensitivity\": 1.04,\n",
      "    \"wrinkle\": 1.0,\n",
      "    \"pigment\": 1.23\n",
      "  },\n",
      "  \"vision_raw\": {\n",
      "    \"acne\": {\n",
      "      \"score\": 15.0,\n",
      "      \"reason\": \"There are a few small areas that appear to be acne, but they are not very prominent.\"\n",
      "    },\n",
      "    \"redness\": {\n",
      "      \"score\": 20.0,\n",
      "      \"reason\": \"Slight redness is observed in some areas, but it's not widespread or intense.\"\n",
      "    },\n",
      "    \"melasma_darkspots\": {\n",
      "      \"score\": 30.0,\n",
      "      \"reason\": \"Some dark spots are visible, indicating the presence of melasma or hyperpigmentation.\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os, json, mimetypes, argparse\n",
    "import cv2, numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from typing import Dict, Tuple, Union\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "TARGET_SHORT = 768\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "PROMPT_TEXT = (\n",
    "    \"전처리된 얼굴 피부 이미지를 분석하여 JSON만 반환하라.\\n\"\n",
    "    \"평가 항목: acne(여드름), redness(홍조), melasma_darkspots(잡티).\\n\"\n",
    "    \"각 항목은 다음 스키마로 제공하라:\\n\"\n",
    "    \"{acne:{score:number,reason:string}, redness:{score:number,reason:string}, \"\n",
    "    \"melasma_darkspots:{score:number,reason:string}}\\n\"\n",
    "    \"score는 0~100 범위의 실수이며, 0은 없음·매우 양호, 100은 매우 심함을 의미한다.\"\n",
    ")\n",
    "\n",
    "\n",
    "def _load_exif_bgr(path: str):\n",
    "    pil = Image.open(path)\n",
    "    pil = ImageOps.exif_transpose(pil).convert(\"RGB\")\n",
    "    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def _resize_short(bgr, short=TARGET_SHORT):\n",
    "    h, w = bgr.shape[:2]\n",
    "    s = min(h, w)\n",
    "    if s == short:\n",
    "        return bgr\n",
    "    scale = short / float(s)\n",
    "    new = (int(round(w * scale)), int(round(h * scale)))\n",
    "    interp = cv2.INTER_AREA if scale < 1.0 else cv2.INTER_CUBIC\n",
    "    return cv2.resize(bgr, new, interpolation=interp)\n",
    "\n",
    "def _wb_grayworld(bgr, strength=0.5):\n",
    "    x = bgr.astype(np.float32)\n",
    "    means = x.reshape(-1,3).mean(0) + 1e-6\n",
    "    g = means.mean()\n",
    "    gains = np.clip(g/means, 0.8, 1.2)\n",
    "    gains = (1-strength)*1.0 + strength*gains\n",
    "    x *= gains\n",
    "    return np.clip(x, 0, 255).astype(np.uint8)\n",
    "\n",
    "def _clahe_light(bgr, clip=1.8, tiles=8):\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = cv2.createCLAHE(clipLimit=clip, tileGridSize=(tiles, tiles)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def _morph_kernel(bgr, base: int = 768, ksize: int = 5):\n",
    "    h, w = bgr.shape[:2]\n",
    "    scale = min(h, w) / float(base)\n",
    "    k = max(3, int(round(ksize * scale)))\n",
    "    if k % 2 == 0:\n",
    "        k += 1\n",
    "    return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))\n",
    "\n",
    "def _skin_mask(bgr):\n",
    "    ycrcb = cv2.cvtColor(bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    Y, Cr, Cb = cv2.split(ycrcb)\n",
    "    m1 = (Cr >= 135) & (Cr <= 180) & (Cb >= 85) & (Cb <= 135) & (Y >= 40) & (Y <= 240)\n",
    "\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "    m2 = (H <= 25) & (S >= 30) & (S <= 180) & (V >= 60)\n",
    "\n",
    "    m = (m1 & m2).astype(np.uint8) * 255\n",
    "\n",
    "    k = _morph_kernel(bgr)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN,  k, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, k, iterations=2)\n",
    "\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(m, connectivity=8)\n",
    "    if num > 1:\n",
    "        largest = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "        m2 = np.zeros_like(m)\n",
    "        m2[labels == largest] = 255\n",
    "        m = m2\n",
    "    return m\n",
    "\n",
    "def preprocess_with_mask(bgr, bg_gray=220, return_mask: bool = False):\n",
    "    bgr = _resize_short(bgr)\n",
    "    bgr = _wb_grayworld(bgr, 0.5)\n",
    "    bgr = _clahe_light(bgr, 1.8, 8)\n",
    "    mask = _skin_mask(bgr)\n",
    "\n",
    "    bg = np.full_like(bgr, (bg_gray, bg_gray, bg_gray), np.uint8)\n",
    "    out = np.where(mask[..., None] == 255, bgr, bg)\n",
    "\n",
    "    if return_mask:\n",
    "        return out, mask\n",
    "    return out\n",
    "\n",
    "\n",
    "def analyze_with_gemini(image_path, api_key):\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"GEMINI_API_KEY 환경 변수가 설정되어 있지 않습니다. 환경 변수를 먼저 설정해 주세요.\")\n",
    "\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    mime = mimetypes.guess_type(image_path)[0] or \"image/jpeg\"\n",
    "\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            img_bytes = f.read()\n",
    "\n",
    "        content = types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=PROMPT_TEXT),\n",
    "                types.Part(inline_data=types.Blob(mime_type=mime, data=img_bytes)),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        resp = client.models.generate_content(\n",
    "            model=MODEL,\n",
    "            contents=[content],\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                temperature=0.2,\n",
    "                system_instruction=\"너는 피부 분석 전문가다. 반드시 JSON만 반환하라.\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        txt = (resp.text or \"\").strip()\n",
    "        start, end = txt.find(\"{\"), txt.rfind(\"}\")\n",
    "        if start == -1 or end == -1:\n",
    "            print(\"[WARN] Gemini 응답에서 JSON 블록을 찾지 못했습니다.\")\n",
    "            print(\"[DEBUG] raw response:\", txt[:300])\n",
    "            return {}\n",
    "        json_str = txt[start:end+1]\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Gemini 응답 JSON 파싱 실패: {e}\")\n",
    "            print(\"[DEBUG] json_str:\", json_str[:300])\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Gemini 분석 중 예외 발생: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "MAP: Dict[str, Dict[str, int]] = {\n",
    "    \"q1\":  {\"없어요\":0,\"T존 일부(이마 혹은 코)\":1,\"T존 전체(이마와 코)\":2,\"얼굴 전체\":3},\n",
    "    \"q2\":  {\"전혀 안 보여요\":0,\"지금은 없지만 가끔 보여요\":1,\"부분적으로 붉게 보여요\":2,\"전체적으로 붉게 보여요\":3},\n",
    "    \"q3\":  {\"없어요\":0,\"U존 일부(볼 혹은 턱)\":1,\"U존 전체(볼과 턱)\":2,\"얼굴 전체\":3},\n",
    "    \"q4\":  {\"전혀 생기지 않아요\":0,\"표정을 지을 때만 생겨요\":1,\"표정 짓지 않아도 약간 있어요\":2,\"표정 짓지 않아도 많이 있어요\":3},\n",
    "    \"q5\":  {\"주름이 없어요\":0,\"잔주름이에요\":1,\"깊은 주름이에요\":2,\"잔주름과 깊은 주름 다 있어요\":3},\n",
    "    \"q6\":  {\"전혀 생기지 않아요\":0,\"미소 지을 때만 약간 생겨요\":1,\"미소 지을 때 진하게 생겨요\":2,\"미소 짓지 않아도 생겨요\":3},\n",
    "    \"q7\":  {\"전혀 안 보여요\":0,\"거의 안 보여요\":1,\"약간 눈에 띄어요\":2,\"곳곳에 많이 보여요\":3},\n",
    "    \"q8\":  {\"주름이 없어요\":0,\"잔주름이에요\":1,\"깊은 주름이에요\":2,\"잔주름과 깊은 주름 다 있어요\":3},\n",
    "    \"q9\":  {\"외출 전보다 윤기가 없어요\":0,\"외출 전과 변함이 없어요\":1,\"약간 번들거리고 윤기가 있어요\":2,\"많이 번들거리고 기름져요\":3},\n",
    "    \"q10\": {\"전혀 안 보여요\":0,\"가끔 붉어지면 보여요\":1,\"특정부위에 눈에 띄어요\":2,\"곳곳에 많이 보여요\":3},\n",
    "}\n",
    "\n",
    "def _to_score(q, v):\n",
    "    return MAP[q].get(v, 0)\n",
    "\n",
    "def _to_0_3(x):\n",
    "    try:\n",
    "        v = float(x)\n",
    "    except Exception:\n",
    "        v = 0.0\n",
    "    return round(max(0, min(100, v)) / 100 * 3, 2)\n",
    "\n",
    "def _decide_skin_type(oil: float, dry: float) -> str:\n",
    "    if oil >= 2 and dry <= 1:\n",
    "        return \"지성\"\n",
    "    if dry >= 2 and oil <= 1:\n",
    "        return \"건성\"\n",
    "    if oil >= 2 and dry >= 2:\n",
    "        return \"복합성\"\n",
    "    return \"중성\"\n",
    "\n",
    "def assess_skin_type(**a):\n",
    "    s = {k: _to_score(k, v) for k, v in a.items()}\n",
    "\n",
    "    oil = round(0.6 * s[\"q1\"] + 0.4 * s[\"q9\"], 2)\n",
    "    dry = float(s[\"q3\"])\n",
    "    sens = round(0.7 * s[\"q2\"] + 0.3 * s[\"q10\"], 2)\n",
    "    wrinkle = round(0.4 * s[\"q4\"] + 0.6 * ((s[\"q5\"] + s[\"q8\"]) / 2), 2)\n",
    "    pigment = float(s[\"q7\"])\n",
    "\n",
    "    skin = _decide_skin_type(oil, dry)\n",
    "\n",
    "    return {\n",
    "        \"skin_type\": skin,\n",
    "        \"indices\": {\n",
    "            \"oil\": oil,\n",
    "            \"dry\": dry,\n",
    "            \"sensitivity\": sens,\n",
    "            \"wrinkle\": wrinkle,\n",
    "            \"pigment\": pigment\n",
    "        }\n",
    "    }\n",
    "\n",
    "def _safe_score(gemini: dict, key: str) -> float:\n",
    "    try:\n",
    "        return _to_0_3(gemini.get(key, {}).get(\"score\", 0))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def assess_with_gemini(survey, gemini):\n",
    "    answers = survey[\"survey\"] if \"survey\" in survey else survey\n",
    "\n",
    "    base = assess_skin_type(**answers)\n",
    "    idx = base[\"indices\"]\n",
    "    fused = idx.copy()\n",
    "\n",
    "    acne  = _safe_score(gemini, \"acne\")\n",
    "    red   = _safe_score(gemini, \"redness\")\n",
    "    mel   = _safe_score(gemini, \"melasma_darkspots\")\n",
    "\n",
    "    fused[\"sensitivity\"] = round(0.4 * idx[\"sensitivity\"] + 0.6 * red,  2)\n",
    "    fused[\"pigment\"]     = round(0.3 * idx[\"pigment\"]     + 0.7 * mel,  2)\n",
    "    fused[\"oil\"]         = round(0.7 * idx[\"oil\"]         + 0.3 * acne, 2)\n",
    "    fused[\"dry\"]         = idx[\"dry\"]\n",
    "    fused[\"wrinkle\"]     = idx[\"wrinkle\"]\n",
    "\n",
    "    skin = _decide_skin_type(fused[\"oil\"], fused[\"dry\"])\n",
    "\n",
    "    return {\n",
    "        \"skin_type\": skin,\n",
    "        \"indices\": fused,\n",
    "        \"vision_raw\": gemini\n",
    "    }\n",
    "\n",
    "\n",
    "def run_fusion_from_request(image_path: str, survey_dict: dict) -> dict:\n",
    "    if not image_path:\n",
    "        raise ValueError(\"image_path가 없습니다. 이미지 파일이 반드시 필요합니다.\")\n",
    "    if \"survey\" not in survey_dict:\n",
    "        raise ValueError(\"survey_dict에 'survey' 키가 없습니다. 설문 JSON이 반드시 필요합니다.\")\n",
    "\n",
    "    answers = survey_dict[\"survey\"]\n",
    "\n",
    "    original = _load_exif_bgr(image_path)\n",
    "    processed = preprocess_with_mask(original)\n",
    "\n",
    "    root, ext = os.path.splitext(image_path)\n",
    "    if not ext:\n",
    "        ext = \".jpg\"\n",
    "    pre_path = f\"{root}_Pre{ext}\"\n",
    "\n",
    "    cv2.imwrite(pre_path, processed)\n",
    "\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    gemini = analyze_with_gemini(pre_path, api_key)\n",
    "\n",
    "    fused = assess_with_gemini({\"survey\": answers}, gemini)\n",
    "    return fused\n",
    "\n",
    "\n",
    "\n",
    "def run_full_pipeline(input_path: str, survey_json_path: str):\n",
    "    original = _load_exif_bgr(input_path)\n",
    "    processed = preprocess_with_mask(original)\n",
    "    root, ext = os.path.splitext(input_path)\n",
    "    if not ext:\n",
    "        ext = \".jpg\"\n",
    "    pre_path = f\"{root}_Pre{ext}\"\n",
    "\n",
    "    cv2.imwrite(pre_path, processed)\n",
    "    print(f\"[INFO] 전처리 완료: {pre_path}\")\n",
    "\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    gemini = analyze_with_gemini(pre_path, api_key)\n",
    "\n",
    "    with open(survey_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        survey = json.load(f)\n",
    "\n",
    "    fused = assess_with_gemini(survey, gemini)\n",
    "\n",
    "    print(\"\\n[설문+이미지 융합 결과]\")\n",
    "    print(json.dumps(fused, ensure_ascii=False, indent=2))\n",
    "\n",
    "    return {\n",
    "        \"preprocessed_image_path\": pre_path,\n",
    "        \"gemini\": gemini,\n",
    "        \"fusion\": fused,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_pipeline(\"Lee.jpg\", \"survey_example.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00dd48d-e16f-422e-a512-a4ecd18c7d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 로드한 문서 수: 243\n",
      "[INFO] bulk indexed 243 docs into cosmetics_demo\n",
      "[INFO] Booster 모델 학습 및 저장 완료: ltr_booster.json\n"
     ]
    }
   ],
   "source": [
    "import json, os, hashlib, re, math\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "except ImportError:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "EMB_MODEL_NAME = \"jhgan/ko-sroberta-multitask\"\n",
    "emb_model = SentenceTransformer(EMB_MODEL_NAME, device=DEVICE)\n",
    "EMB_DIM = emb_model.get_sentence_embedding_dimension()\n",
    "\n",
    "INDEX_NAME = \"cosmetics_demo\"\n",
    "_SPLIT_RE = re.compile(r\"[,\\s/;·∙•ㆍ|]+\")\n",
    "CATEGORIES = [\"cream\", \"essence\", \"skintoner\"]\n",
    "LTR_MODEL_PATH = \"ltr_booster.json\"\n",
    "\n",
    "\n",
    "def connect_es() -> Elasticsearch:\n",
    "    url = os.getenv(\"ES_URL\", \"http://localhost:9200\")\n",
    "    return Elasticsearch(url, request_timeout=20)\n",
    "\n",
    "\n",
    "def load_json(path: str) -> List[Dict[str, Any]]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def _split_ingredients(ing: str) -> List[str]:\n",
    "    if not ing:\n",
    "        return []\n",
    "    parts = _SPLIT_RE.split(ing)\n",
    "    return [p.strip().lower() for p in parts if p.strip()]\n",
    "\n",
    "\n",
    "def normalize_product(doc: Dict[str, Any], category: str) -> Dict[str, Any]:\n",
    "    name = doc.get(\"productName\") or \"\"\n",
    "    brand = doc.get(\"mallName\") or \"\"\n",
    "    sale = doc.get(\"salePrice\")\n",
    "    if isinstance(sale, str):\n",
    "        nums = re.findall(r\"\\d[\\d,._]*\", sale.replace(\" \", \"\"))\n",
    "        sale = float(nums[0].replace(\",\", \"\").replace(\"_\", \"\")) if nums else None\n",
    "\n",
    "    avg_score = doc.get(\"averageReviewScore\")\n",
    "    review_cnt = doc.get(\"totalReviewCount\")\n",
    "\n",
    "    ing_str = (doc.get(\"ingredientsInfo\") or {}).get(\"ingredients\")\n",
    "    ingredients = _split_ingredients(ing_str) if isinstance(ing_str, str) else []\n",
    "\n",
    "    reviews = doc.get(\"reviews\") or []\n",
    "    review_text = \" \".join([str(r.get(\"reviewContent\", \"\")) for r in reviews])[:5000]\n",
    "\n",
    "    pid = hashlib.md5(f\"{name}|{brand}\".encode(\"utf-8\")).hexdigest()\n",
    "    return {\n",
    "        \"product_id\": pid,\n",
    "        \"productName\": name,\n",
    "        \"brand\": brand,\n",
    "        \"category\": category,\n",
    "        \"ingredients\": ingredients,\n",
    "        \"review_text\": review_text,\n",
    "        \"salePrice\": sale,\n",
    "        \"averageReviewScore\": avg_score,\n",
    "        \"totalReviewCount\": review_cnt,\n",
    "    }\n",
    "\n",
    "\n",
    "def load_and_normalize_all() -> List[Dict[str, Any]]:\n",
    "    base = os.getcwd()\n",
    "    files = [\n",
    "        (os.path.join(base, \"cream.json\"), \"cream\"),\n",
    "        (os.path.join(base, \"essence.json\"), \"essence\"),\n",
    "        (os.path.join(base, \"essense.json\"), \"essence\"),\n",
    "        (os.path.join(base, \"skintoner.json\"), \"skintoner\"),\n",
    "    ]\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    for path, cat in files:\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        try:\n",
    "            raw = load_json(path)\n",
    "            for doc in raw:\n",
    "                out.append(normalize_product(doc, cat))\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {path}: {e}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def encode_texts_batch(texts: List[str], batch_size: int = 64) -> np.ndarray:\n",
    "    if not texts:\n",
    "        return np.zeros((0, EMB_DIM), dtype=np.float32)\n",
    "    vecs = emb_model.encode(\n",
    "        texts,\n",
    "        normalize_embeddings=True,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=False,\n",
    "    )\n",
    "    return np.asarray(vecs, dtype=np.float32)\n",
    "\n",
    "\n",
    "def add_review_vectors_batch(docs: List[Dict[str, Any]], batch_size: int = 64) -> List[Dict[str, Any]]:\n",
    "    texts = [d.get(\"review_text\", \"\") or \"\" for d in docs]\n",
    "    if not texts:\n",
    "        return docs\n",
    "    vecs = encode_texts_batch(texts, batch_size=batch_size)\n",
    "    for d, v in zip(docs, vecs):\n",
    "        d[\"review_vector\"] = v.tolist()\n",
    "    return docs\n",
    "\n",
    "\n",
    "def ensure_index_minimal(es: Elasticsearch):\n",
    "    if es.indices.exists(index=INDEX_NAME):\n",
    "        return\n",
    "\n",
    "    body = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"product_id\": {\"type\": \"keyword\"},\n",
    "                \"productName\": {\"type\": \"text\"},\n",
    "                \"brand\": {\"type\": \"keyword\"},\n",
    "                \"category\": {\"type\": \"keyword\"},\n",
    "                \"ingredients\": {\"type\": \"text\"},\n",
    "                \"review_text\": {\"type\": \"text\"},\n",
    "                \"salePrice\": {\"type\": \"float\"},\n",
    "                \"averageReviewScore\": {\"type\": \"float\"},\n",
    "                \"totalReviewCount\": {\"type\": \"integer\"},\n",
    "                \"review_vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": EMB_DIM,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\",\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=INDEX_NAME, body=body)\n",
    "    print(f\"[INFO] index created: {INDEX_NAME}\")\n",
    "\n",
    "\n",
    "def bulk_index(es: Elasticsearch, docs: List[Dict[str, Any]]):\n",
    "    ops = (\n",
    "        {\n",
    "            \"_op_type\": \"index\",\n",
    "            \"_index\": INDEX_NAME,\n",
    "            \"_id\": d[\"product_id\"],\n",
    "            \"_source\": d,\n",
    "        }\n",
    "        for d in docs\n",
    "    )\n",
    "    helpers.bulk(es, ops, refresh=\"wait_for\")\n",
    "    print(f\"[INFO] bulk indexed {len(docs)} docs into {INDEX_NAME}\")\n",
    "\n",
    "\n",
    "POS_ING = {\n",
    "    \"pigment\": {\n",
    "        \"niacinamide\", \"나이아신아마이드\",\n",
    "        \"vitamin c\", \"비타민c\",\n",
    "        \"ascorbic\", \"아스코빅\",\n",
    "        \"arbutin\", \"아르부틴\",\n",
    "        \"tranexamic\", \"트라넥삼산\",\n",
    "        \"licorice\", \"감초\",\n",
    "        \"kojic\", \"코직\",\n",
    "    },\n",
    "    \"sensitivity\": {\n",
    "        \"panthenol\", \"판테놀\",\n",
    "        \"madecassoside\", \"마데카소사이드\",\n",
    "        \"centella\", \"병풀\",\n",
    "        \"cica\", \"시카\",\n",
    "        \"allantoin\", \"알란토인\",\n",
    "        \"beta-glucan\", \"베타글루칸\",\n",
    "        \"bisabolol\", \"비사볼올\",\n",
    "        \"aloe\", \"알로에\",\n",
    "        \"ceramide\", \"세라마이드\",\n",
    "    },\n",
    "    \"dry\": {\n",
    "        \"hyaluronic\", \"히알루론산\",\n",
    "        \"glycerin\", \"글리세린\",\n",
    "        \"squalane\", \"스쿠알란\",\n",
    "        \"ceramide\", \"세라마이드\",\n",
    "        \"cholesterol\", \"콜레스테롤\",\n",
    "        \"urea\", \"요소\",\n",
    "    },\n",
    "    \"acne\": {\n",
    "        \"salicylic\", \"살리실산\",\n",
    "        \"bha\", \"바하\",\n",
    "        \"azelaic\", \"아젤라익\",\n",
    "        \"zinc\", \"아연\",\n",
    "    },\n",
    "}\n",
    "\n",
    "NEG_ING = {\n",
    "    \"sensitivity\": {\n",
    "        \"fragrance\", \"향료\", \"향\",\n",
    "        \"parfum\", \"퍼퓸\",\n",
    "        \"alcohol\", \"알코올\", \"에탄올\",\n",
    "        \"essential oil\", \"에센셜 오일\",\n",
    "        \"tea tree oil\", \"티트리 오일\",\n",
    "    },\n",
    "    \"acne\": {\n",
    "        \"coconut oil\", \"코코넛 오일\",\n",
    "        \"isopropyl myristate\", \"아이소프로필 미리스테이트\",\n",
    "        \"lanolin\", \"라놀린\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def fusion_to_query_text(fusion: Dict[str, Any]) -> str:\n",
    "    idx = fusion.get(\"indices\", {})\n",
    "    skin = fusion.get(\"skin_type\", \"\")\n",
    "\n",
    "    oil = float(idx.get(\"oil\", 0.0))\n",
    "    dry = float(idx.get(\"dry\", 0.0))\n",
    "    sens = float(idx.get(\"sensitivity\", 0.0))\n",
    "    wrinkle = float(idx.get(\"wrinkle\", 0.0))\n",
    "    pigment = float(idx.get(\"pigment\", 0.0))\n",
    "\n",
    "    parts: List[str] = []\n",
    "\n",
    "    if skin:\n",
    "        parts.append(f\"피부 타입은 {skin} 피부입니다.\")\n",
    "    if oil >= 2.0:\n",
    "        parts.append(\"피지가 많고 번들거림이 고민입니다.\")\n",
    "    elif oil <= 1.0:\n",
    "        parts.append(\"유분은 많지 않습니다.\")\n",
    "    if dry >= 2.0:\n",
    "        parts.append(\"건조하고 당김이 느껴집니다.\")\n",
    "    if sens >= 2.0:\n",
    "        parts.append(\"민감성과 자극, 붉은기 고민이 큽니다.\")\n",
    "    if pigment >= 2.0:\n",
    "        parts.append(\"기미, 잡티, 색소침착 개선을 원합니다.\")\n",
    "    if wrinkle >= 2.0:\n",
    "        parts.append(\"주름과 탄력 저하도 고민입니다.\")\n",
    "    parts.append(\"자극이 적고 트러블이 덜 나며 피부 진정과 개선에 도움이 된다는 후기가 많은 제품을 선호합니다.\")\n",
    "\n",
    "    return \" \".join(parts)\n",
    "\n",
    "\n",
    "def encode_query_text(text: str) -> List[float]:\n",
    "    if not text:\n",
    "        return [0.0] * EMB_DIM\n",
    "    vec = emb_model.encode(text, normalize_embeddings=True)\n",
    "    return vec.tolist()\n",
    "\n",
    "\n",
    "def encode_query_from_fusion(fusion: Dict[str, Any]) -> List[float]:\n",
    "    text = fusion_to_query_text(fusion)\n",
    "    return encode_query_text(text)\n",
    "\n",
    "\n",
    "def _ing_filter(ings: List[str]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"bool\": {\n",
    "            \"should\": [{\"match_phrase\": {\"ingredients\": ing}} for ing in ings],\n",
    "            \"minimum_should_match\": 1,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def build_query(\n",
    "    fusion: Dict[str, Any],\n",
    "    category: str,\n",
    "    top_k: int,\n",
    "    query_vec: List[float],\n",
    ") -> Dict[str, Any]:\n",
    "    idx = fusion.get(\"indices\", {})\n",
    "    oil = float(idx.get(\"oil\", 0.0))\n",
    "    dry = float(idx.get(\"dry\", 0.0))\n",
    "    sens = float(idx.get(\"sensitivity\", 0.0))\n",
    "    pigment = float(idx.get(\"pigment\", 0.0))\n",
    "    acne_flag = 1.0 if fusion.get(\"flags\", {}).get(\"acne\") else 0.0\n",
    "\n",
    "    pos_ings = set()\n",
    "    if pigment >= 2.0:\n",
    "        pos_ings |= POS_ING[\"pigment\"]\n",
    "    if sens >= 2.0:\n",
    "        pos_ings |= POS_ING[\"sensitivity\"]\n",
    "    if dry >= 2.0:\n",
    "        pos_ings |= POS_ING[\"dry\"]\n",
    "    if oil >= 2.0 or acne_flag:\n",
    "        pos_ings |= POS_ING[\"acne\"]\n",
    "\n",
    "    functions = []\n",
    "\n",
    "    functions.append({\n",
    "        \"script_score\": {\n",
    "            \"script\": {\n",
    "                \"source\": \"\"\"\n",
    "                    double sim = cosineSimilarity(params.qvec, 'review_vector');\n",
    "                    sim = (sim + 1.0) / 2.0;\n",
    "\n",
    "                    double bonus = 0.0;\n",
    "                    if (!doc['averageReviewScore'].empty) {\n",
    "                        double r = Math.min(Math.max(doc['averageReviewScore'].value, 0.0), 5.0);\n",
    "                        bonus += (r / 5.0) * 0.5;\n",
    "                    }\n",
    "                    if (!doc['totalReviewCount'].empty) {\n",
    "                        double n = Math.min(doc['totalReviewCount'].value, 5000);\n",
    "                        bonus += (n / 5000.0) * 0.5;\n",
    "                    }\n",
    "\n",
    "                    return 1.0 + 5.0 * sim + bonus;\n",
    "                \"\"\",\n",
    "                \"params\": {\n",
    "                    \"qvec\": query_vec\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    if pos_ings:\n",
    "        functions.append({\n",
    "            \"filter\": _ing_filter(list(pos_ings)),\n",
    "            \"weight\": 3.0\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"function_score\": {\n",
    "                \"query\": {\"term\": {\"category\": category}},\n",
    "                \"score_mode\": \"sum\",\n",
    "                \"boost_mode\": \"sum\",\n",
    "                \"functions\": functions\n",
    "            }\n",
    "        },\n",
    "        \"_source\": {\n",
    "            \"includes\": [\n",
    "                \"product_id\", \"productName\", \"brand\", \"category\",\n",
    "                \"ingredients\", \"salePrice\", \"averageReviewScore\",\n",
    "                \"totalReviewCount\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def search_candidates_per_category(es: Elasticsearch, fusion: Dict[str, Any], per_cat: int = 30):\n",
    "    query_vec = encode_query_from_fusion(fusion)\n",
    "    out: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for cat in CATEGORIES:\n",
    "        body = build_query(fusion, cat, per_cat, query_vec)\n",
    "        resp = es.search(index=INDEX_NAME, body=body)\n",
    "        hits = resp.get(\"hits\", {}).get(\"hits\", [])\n",
    "        out[cat] = [\n",
    "            {\n",
    "                \"rank_es\": i + 1,\n",
    "                \"score_es\": h[\"_score\"],\n",
    "                **h[\"_source\"],\n",
    "            }\n",
    "            for i, h in enumerate(hits)\n",
    "        ]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _make_pos_neg_vocab(fusion: Dict[str, Any]) -> Tuple[set, set]:\n",
    "    idx = fusion.get(\"indices\", {})\n",
    "    oil = float(idx.get(\"oil\", 0.0))\n",
    "    dry = float(idx.get(\"dry\", 0.0))\n",
    "    sens = float(idx.get(\"sensitivity\", 0.0))\n",
    "    pigment = float(idx.get(\"pigment\", 0.0))\n",
    "    acne = 1.0 if fusion.get(\"flags\", {}).get(\"acne\") else 0.0\n",
    "    pos, neg = set(), set()\n",
    "    if pigment >= 2.0:\n",
    "        pos |= POS_ING[\"pigment\"]\n",
    "    if sens >= 2.0:\n",
    "        pos |= POS_ING[\"sensitivity\"]\n",
    "        neg |= NEG_ING[\"sensitivity\"]\n",
    "    if dry >= 2.0:\n",
    "        pos |= POS_ING[\"dry\"]\n",
    "    if oil >= 2.0 or acne:\n",
    "        pos |= POS_ING[\"acne\"]\n",
    "        neg |= NEG_ING[\"acne\"]\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "def _ingredients_hits(ingredients, vocab):\n",
    "    return sum(1 for x in (ingredients or []) if x in vocab)\n",
    "\n",
    "\n",
    "def _safe_log1p(x):\n",
    "    try:\n",
    "        return math.log1p(float(x)) if x else 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def featurize(results_by_cat: Dict[str, List[Dict[str, Any]]], fusion: Dict[str, Any]):\n",
    "    pos_vocab, neg_vocab = _make_pos_neg_vocab(fusion)\n",
    "    X, group = [], []\n",
    "\n",
    "    for cat in CATEGORIES:\n",
    "        rows = results_by_cat.get(cat, [])\n",
    "        group.append(len(rows))\n",
    "\n",
    "        for r in rows:\n",
    "            ingredients = r.get(\"ingredients\") or []\n",
    "            pos_hits = _ingredients_hits(ingredients, pos_vocab)\n",
    "            neg_hits = _ingredients_hits(ingredients, neg_vocab)\n",
    "            pos_ratio = (pos_hits / max(1, len(ingredients))) if ingredients else 0.0\n",
    "\n",
    "            avg = r.get(\"averageReviewScore\")\n",
    "            cnt = r.get(\"totalReviewCount\")\n",
    "            price = r.get(\"salePrice\")\n",
    "            es_score = r.get(\"score_es\", 0.0)\n",
    "\n",
    "            X.append(\n",
    "                [\n",
    "                    pos_hits,\n",
    "                    neg_hits,\n",
    "                    pos_hits - neg_hits,\n",
    "                    pos_ratio,\n",
    "                    avg or 0.0,\n",
    "                    _safe_log1p(cnt),\n",
    "                    _safe_log1p(price),\n",
    "                    es_score,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return X, group\n",
    "\n",
    "\n",
    "def train_booster_offline(es: Elasticsearch, fusion_json: Dict[str, Any], model_path: str = LTR_MODEL_PATH):\n",
    "    import xgboost as xgb\n",
    "\n",
    "    es_results = search_candidates_per_category(es, fusion_json, per_cat=30)\n",
    "    X, group = featurize(es_results, fusion_json)\n",
    "    if not X:\n",
    "        raise RuntimeError(\"LTR 학습을 위한 후보 데이터가 없습니다.\")\n",
    "\n",
    "    X_arr = np.asarray(X, dtype=np.float32)\n",
    "    y_list: List[float] = []\n",
    "    for cat in CATEGORIES:\n",
    "        rows = es_results.get(cat, [])\n",
    "        y_list.extend(float(len(rows) - i) for i, _ in enumerate(rows))\n",
    "    y_arr = np.asarray(y_list, dtype=np.float32)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_arr, label=y_arr)\n",
    "    dtrain.set_group(group)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"rank:pairwise\",\n",
    "        \"eta\": 0.1,\n",
    "        \"max_depth\": 5,\n",
    "        \"eval_metric\": \"ndcg\",\n",
    "    }\n",
    "\n",
    "    booster = xgb.train(params, dtrain, num_boost_round=80)\n",
    "    booster.save_model(model_path)\n",
    "    print(f\"[INFO] Booster 모델 학습 및 저장 완료: {model_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    es = connect_es()\n",
    "    ensure_index_minimal(es)\n",
    "\n",
    "    docs = load_and_normalize_all()\n",
    "    if docs:\n",
    "        print(f\"[INFO] 로드한 문서 수: {len(docs)}\")\n",
    "        docs = add_review_vectors_batch(docs, batch_size=64)\n",
    "        bulk_index(es, docs)\n",
    "\n",
    "    fusion_json = {\n",
    "        \"skin_type\": \"복합성\",\n",
    "        \"indices\": {\n",
    "            \"oil\": 2.2,\n",
    "            \"dry\": 1.0,\n",
    "            \"sensitivity\": 2.4,\n",
    "            \"wrinkle\": 1.2,\n",
    "            \"pigment\": 2.8,\n",
    "        },\n",
    "        \"flags\": {\"sensitive\": True, \"aging\": False, \"pigment\": True, \"acne\": False},\n",
    "    }\n",
    "\n",
    "    train_booster_offline(es, fusion_json, LTR_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7326dc7-6e19-4994-b52b-782b18e74443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CREAM (ES candidates) ---\n",
      "- (10.2172) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 EDLP 어성초 71% 수분크림(대용량) 120g /수분진정 속건조개선 민감지성피부 촘촘보습 2배용량 수분만땅 | 8000\n",
      "- (10.1608) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 레티날 300ppm 크림 30ml /비타민 A 레티날 레티놀 리프팅 주름개선 크림 | 9000\n",
      "- (10.0970) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 EDLP 어성초 71% 수분크림 60g /속건조개선 민감지성피부 열감감소 수분가득 촉촉크림 | 5200\n",
      "- (10.0834) 달바 공식스토어 | 달바 비건 더블 크림 단지형 70g | 78000\n",
      "- (10.0327) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 세라판테놀 8% 인텐시브 크림 (세라마이드 10,000ppm) 50ml /고보습크림 보습영양 탄력크림 속보습 장벽케어크림 | 9000\n",
      "- (10.0315) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 레티날 1000ppm 크림 30ml /비타민A 레티날 레티놀 모공탄력 깐달걀피부 리프팅 미백 주름개선 레틴A 탄력세럼 포 | 15000\n",
      "- (10.0277) 마몽드 | [싱글] 마몽드 포어 슈링커 바쿠치올 크림 60ml x 1개 | 38000\n",
      "- (9.9825) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 레티노이드 4000ppm 크림 30ml/비타민A 판테놀 리프팅 미백 주름개선 탄력크림 레티놀 3000ppm 레티날 100 | 20000\n",
      "- (9.9604) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 더블화이트닝크림 40ml (20ml+20ml) / 반반크림 미백크림 미백케어 잡티케어 글루타치온 투명한피부 톤케어 브라이 | 12000\n",
      "- (9.9197) 한율 | [본사직영] 한율 어린쑥 수분진정크림 55ml /한율 1등템 | 38000\n",
      "- (9.9161) 달바 공식스토어 | 달바 비건 더블 크림 튜브형 60ml | 62000\n",
      "- (9.9124) 비욘드 Beyond | 비욘드 수분크림 1+1 엔젤아쿠아 시카크림 (150mL + 150mL) (비건) | 26000\n",
      "- (9.8798) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 트라넥삼산(트라넥사믹애씨드) 6%크림 30ml /미백 기미크림 화이트닝 멜라닌 잡티크림 밝은피부 투명피부 미백기능성 다크 | 8000\n",
      "- (9.8621) 브링그린 | 브링그린 대나무 히알루 수분 부스팅 크림 100ml + 100ml | 34200\n",
      "- (9.8341) 어퓨 공식스토어 | [어퓨] 마데카소사이드 테트라좀 시카 크림 | 28000\n",
      "\n",
      "--- ESSENCE (ES candidates) ---\n",
      "- (10.2289) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 나이아신아마이드 20%(200,000ppm) 세럼 30ml /모공세럼 브라이트닝 모공탄력 모공쫀쫀 결케어 맑은피부케어 비 | 6000\n",
      "- (10.1128) 더마펌 | 더마펌 수딩 리페어 바쿠치올 토닝세럼 R4 잡티흔적케어 30ml | 39000\n",
      "- (10.0770) 스킨푸드 | [스킨푸드][마스크 5매+크림 미니 증정] 캐롯 카로틴 모이스트 진정 수분 앰플 이펙터 55m_당근앰플 | 27000\n",
      "- (10.0580) 이니스프리 | 이니스프리 그린티 씨드 히알루론산 수분세럼 / 진정 보습 속건조 화잘먹 | 62000\n",
      "- (9.9204) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 나이아신아마이드 20%(200,000ppm) 세럼 한글에디션 80ml/모공세럼 브라이트닝 모공탄력 결케어 맑은피부케어 비 | 14000\n",
      "- (9.8889) 토리든 | [2종세트]토리든 다이브인 히알루론산 세럼 50ml+40ml +(다이브인 멀티패드 2매입x2개) | 42000\n",
      "- (9.8777) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 시카60.2%앰플 30ml/진정앰플 민감피부진정 빠른진정 긴급진정 센텔라정량추출물 TECA 병풀 카밍 산뜻앰플 | 9000\n",
      "- (9.8672) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 리얼베라 모공세럼 30ml /모공케어 가로모공 세로모공 모공타이트닝 블랙헤드 모공탄력 모공축소 | 8000\n",
      "- (9.8278) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 나이아신 알파알부틴 17% 세럼 30ml / 알파알부틴 나이아신아마이드 말끔톤케어 브라이트닝 밀착케어 근본미백 | 9000\n",
      "- (9.8177) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 매트릭실 15% 멀티 링클 세럼 30ml / 멀티주름케어 눈가주름 매트릭실 아지렐린 카르노신 특허펩타이드 펩타이드세럼 저 | 15000\n",
      "- (9.7949) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 레티날 시카 앰플 30ml /비타민A 레티날 레티놀 입문자용 병풀 모공탄력 깐달걀피부 리프팅 미백 주름개선 레틴A 탄력세 | 9000\n",
      "- (9.7419) 에르쯔틴공식몰 | [에르쯔틴] 히아세라 모이스처 시카 앰플 190ml | 33000\n",
      "- (9.7415) 스킨푸드 | [스킨푸드] 샤인머스캣 시카 바하 진정 피부결 세럼 50ml | 27000\n",
      "- (9.7360) .solution 닷솔루션 | [도착보장] 닷솔루션 씨솔루션 히알루론 시카 수딩 세럼 | 18000\n",
      "- (9.7290) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 나이아신 트라넥삼산 13% 세럼 30ml/잡티세럼 미백세럼 글루타치온 비타민C 데일리미백 저자극 투명광채 나이아신아마이드 | 8000\n",
      "\n",
      "--- SKINTONER (ES candidates) ---\n",
      "- (10.9330) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 데일리 모공 토너 150ml / 수분필링 결케어 피지연화토너 블랙헤드 화이트헤드 피부광채 AHA BHA PHA LHA 각 | 9000\n",
      "- (10.8625) 에센허브 공식몰 | 에센허브 비건 티트리 카밍토너320ml | 34000\n",
      "- (10.7527) 싸이닉 공식스토어 | 싸이닉 더 심플 비건 카밍 토너 145ml / 비건 수부지 진정 토너 | 15000\n",
      "- (10.7391) 이니스프리 | 이니스프리 그린티 히알루론산 스킨 / 저자극 수부지 속건조 170ml, 3개 | 57000\n",
      "- (10.7262) 싸이닉 공식스토어 | [초대용량/1+1] 싸이닉 더 심플 비건 카밍 토너 대용량 500ml / 비건 수부지 진정 토너 | 50000\n",
      "- (10.6835) 한율 | [본사직영] 한율 어린쑥 수분진정 토너 150ml | 27000\n",
      "- (10.6160) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 비제로 마일드 토너 250ml / n스킨 n겹토너 자극지수 0.00 저자극 민감피부 물토너 수분보습 흡토 닦토 토너팩 덱 | 6800\n",
      "- (10.5869) .solution 닷솔루션 | 에이솔루션 아크네 클리어 어성초 토너 | 24000\n",
      "- (10.5593) 디어클레어스 | 클레어스 서플 프레퍼레이션 페이셜 에센스 토너 180ml / 속건조 수분 보습 진정 | 19900\n",
      "- (10.5427) 디어클레어스 | 클레어스 서플 프레퍼레이션 언센티드 에센스 토너 180ml / 속건조 수분 보습 진정 | 19900\n",
      "- (10.4517) 브리스킨 | 브리스킨 엑소좀토너 부활초 엑소펩타이드 스킨부스터 400ml 대용량 | 68000\n",
      "- (10.4392) 에뛰드 본사직영샵 | [에뛰드] 순정 약산성 5.5 진정 토너 | 35000\n",
      "- (10.4060) 테라로직 | 테라로직 펜타마이드 리얼 브라이트닝 토너 280ml, 1개 | 32000\n",
      "- (10.3971) 마몽드 | [싱글] 마몽드 플로라 글로우 로즈 워터 토너 500ml x 1개 | 25000\n",
      "- (10.3626) 보나쥬르 | 보나쥬르 센텔라 리페어 비건 스킨 / 진정피지케어 지복합성 산뜻 토너 150ml | 26000\n",
      "\n",
      "===  CATEGORY TOP-3 (after LTR) ===\n",
      "\n",
      "[CREAM]\n",
      "- (LTR:2.4156 | ES:10.1608) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 레티날 300ppm 크림 30ml /비타민 A 레티날 레티놀 리프팅 주름개선 크림 | 9000\n",
      "- (LTR:1.9984 | ES:10.2172) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 EDLP 어성초 71% 수분크림(대용량) 120g /수분진정 속건조개선 민감지성피부 촘촘보습 2배용량 수분만땅 | 8000\n",
      "- (LTR:1.9060 | ES:10.0970) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 EDLP 어성초 71% 수분크림 60g /속건조개선 민감지성피부 열감감소 수분가득 촉촉크림 | 5200\n",
      "\n",
      "[ESSENCE]\n",
      "- (LTR:2.3440 | ES:10.2289) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 나이아신아마이드 20%(200,000ppm) 세럼 30ml /모공세럼 브라이트닝 모공탄력 모공쫀쫀 결케어 맑은피부케어 비 | 6000\n",
      "- (LTR:1.8046 | ES:10.1128) 더마펌 | 더마펌 수딩 리페어 바쿠치올 토닝세럼 R4 잡티흔적케어 30ml | 39000\n",
      "- (LTR:1.7029 | ES:10.0770) 스킨푸드 | [스킨푸드][마스크 5매+크림 미니 증정] 캐롯 카로틴 모이스트 진정 수분 앰플 이펙터 55m_당근앰플 | 27000\n",
      "\n",
      "[SKINTONER]\n",
      "- (LTR:2.0870 | ES:10.9330) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 데일리 모공 토너 150ml / 수분필링 결케어 피지연화토너 블랙헤드 화이트헤드 피부광채 AHA BHA PHA LHA 각 | 9000\n",
      "- (LTR:1.9624 | ES:10.8625) 에센허브 공식몰 | 에센허브 비건 티트리 카밍토너320ml | 34000\n",
      "- (LTR:1.8088 | ES:10.7527) 싸이닉 공식스토어 | 싸이닉 더 심플 비건 카밍 토너 145ml / 비건 수부지 진정 토너 | 15000\n"
     ]
    }
   ],
   "source": [
    "import os, math\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "except ImportError:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "EMB_MODEL_NAME = \"jhgan/ko-sroberta-multitask\"\n",
    "emb_model = SentenceTransformer(EMB_MODEL_NAME, device=DEVICE)\n",
    "EMB_DIM = emb_model.get_sentence_embedding_dimension()\n",
    "\n",
    "INDEX_NAME = \"cosmetics_demo\"\n",
    "CATEGORIES = [\"cream\", \"essence\", \"skintoner\"]\n",
    "LTR_MODEL_PATH = \"ltr_booster.json\"\n",
    "\n",
    "\n",
    "def connect_es() -> Elasticsearch:\n",
    "    url = os.getenv(\"ES_URL\", \"http://localhost:9200\")\n",
    "    return Elasticsearch(url, request_timeout=20)\n",
    "\n",
    "\n",
    "POS_ING = {\n",
    "    \"pigment\": {\n",
    "        \"niacinamide\", \"나이아신아마이드\",\n",
    "        \"vitamin c\", \"비타민c\",\n",
    "        \"ascorbic\", \"아스코빅\",\n",
    "        \"arbutin\", \"아르부틴\",\n",
    "        \"tranexamic\", \"트라넥삼산\",\n",
    "        \"licorice\", \"감초\",\n",
    "        \"kojic\", \"코직\",\n",
    "    },\n",
    "    \"sensitivity\": {\n",
    "        \"panthenol\", \"판테놀\",\n",
    "        \"madecassoside\", \"마데카소사이드\",\n",
    "        \"centella\", \"병풀\",\n",
    "        \"cica\", \"시카\",\n",
    "        \"allantoin\", \"알란토인\",\n",
    "        \"beta-glucan\", \"베타글루칸\",\n",
    "        \"bisabolol\", \"비사볼올\",\n",
    "        \"aloe\", \"알로에\",\n",
    "        \"ceramide\", \"세라마이드\",\n",
    "    },\n",
    "    \"dry\": {\n",
    "        \"hyaluronic\", \"히알루론산\",\n",
    "        \"glycerin\", \"글리세린\",\n",
    "        \"squalane\", \"스쿠알란\",\n",
    "        \"ceramide\", \"세라마이드\",\n",
    "        \"cholesterol\", \"콜레스테롤\",\n",
    "        \"urea\", \"요소\",\n",
    "    },\n",
    "    \"acne\": {\n",
    "        \"salicylic\", \"살리실산\",\n",
    "        \"bha\", \"바하\",\n",
    "        \"azelaic\", \"아젤라익\",\n",
    "        \"zinc\", \"아연\",\n",
    "    },\n",
    "}\n",
    "\n",
    "NEG_ING = {\n",
    "    \"sensitivity\": {\n",
    "        \"fragrance\", \"향료\", \"향\",\n",
    "        \"parfum\", \"퍼퓸\",\n",
    "        \"alcohol\", \"알코올\", \"에탄올\",\n",
    "        \"essential oil\", \"에센셜 오일\",\n",
    "        \"tea tree oil\", \"티트리 오일\",\n",
    "    },\n",
    "    \"acne\": {\n",
    "        \"coconut oil\", \"코코넛 오일\",\n",
    "        \"isopropyl myristate\", \"아이소프로필 미리스테이트\",\n",
    "        \"lanolin\", \"라놀린\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def encode_query_text(text: str) -> List[float]:\n",
    "    if not text:\n",
    "        return [0.0] * EMB_DIM\n",
    "    vec = emb_model.encode(text, normalize_embeddings=True)\n",
    "    return vec.tolist()\n",
    "\n",
    "\n",
    "def fusion_to_query_text(fusion: Dict[str, Any]) -> str:\n",
    "    idx = fusion.get(\"indices\", {})\n",
    "    skin = fusion.get(\"skin_type\", \"\")\n",
    "\n",
    "    oil = float(idx.get(\"oil\", 0.0))\n",
    "    dry = float(idx.get(\"dry\", 0.0))\n",
    "    sens = float(idx.get(\"sensitivity\", 0.0))\n",
    "    wrinkle = float(idx.get(\"wrinkle\", 0.0))\n",
    "    pigment = float(idx.get(\"pigment\", 0.0))\n",
    "\n",
    "    parts: List[str] = []\n",
    "\n",
    "    if skin:\n",
    "        parts.append(f\"피부 타입은 {skin} 피부입니다.\")\n",
    "    if oil >= 2.0:\n",
    "        parts.append(\"피지가 많고 번들거림이 고민입니다.\")\n",
    "    elif oil <= 1.0:\n",
    "        parts.append(\"유분은 많지 않습니다.\")\n",
    "    if dry >= 2.0:\n",
    "        parts.append(\"건조하고 당김이 느껴집니다.\")\n",
    "    if sens >= 2.0:\n",
    "        parts.append(\"민감성과 자극, 붉은기 고민이 큽니다.\")\n",
    "    if pigment >= 2.0:\n",
    "        parts.append(\"기미, 잡티, 색소침착 개선을 원합니다.\")\n",
    "    if wrinkle >= 2.0:\n",
    "        parts.append(\"주름과 탄력 저하도 고민입니다.\")\n",
    "    parts.append(\"자극이 적고 트러블이 덜 나며 피부 진정과 개선에 도움이 된다는 후기가 많은 제품을 선호합니다.\")\n",
    "\n",
    "    return \" \".join(parts)\n",
    "\n",
    "\n",
    "def encode_query_from_fusion(fusion: Dict[str, Any]) -> List[float]:\n",
    "    text = fusion_to_query_text(fusion)\n",
    "    return encode_query_text(text)\n",
    "\n",
    "\n",
    "def _ing_filter(ings: List[str]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"bool\": {\n",
    "            \"should\": [{\"match_phrase\": {\"ingredients\": ing}} for ing in ings],\n",
    "            \"minimum_should_match\": 1,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def build_query(\n",
    "    fusion: Dict[str, Any],\n",
    "    category: str,\n",
    "    top_k: int,\n",
    "    query_vec: List[float],\n",
    ") -> Dict[str, Any]:\n",
    "    idx = fusion.get(\"indices\", {})\n",
    "    oil = float(idx.get(\"oil\", 0.0))\n",
    "    dry = float(idx.get(\"dry\", 0.0))\n",
    "    sens = float(idx.get(\"sensitivity\", 0.0))\n",
    "    pigment = float(idx.get(\"pigment\", 0.0))\n",
    "    acne_flag = 1.0 if fusion.get(\"flags\", {}).get(\"acne\") else 0.0\n",
    "\n",
    "    pos_ings = set()\n",
    "    if pigment >= 2.0:\n",
    "        pos_ings |= POS_ING[\"pigment\"]\n",
    "    if sens >= 2.0:\n",
    "        pos_ings |= POS_ING[\"sensitivity\"]\n",
    "    if dry >= 2.0:\n",
    "        pos_ings |= POS_ING[\"dry\"]\n",
    "    if oil >= 2.0 or acne_flag:\n",
    "        pos_ings |= POS_ING[\"acne\"]\n",
    "\n",
    "    functions = []\n",
    "\n",
    "    functions.append({\n",
    "        \"script_score\": {\n",
    "            \"script\": {\n",
    "                \"source\": \"\"\"\n",
    "                    double sim = cosineSimilarity(params.qvec, 'review_vector');\n",
    "                    sim = (sim + 1.0) / 2.0;\n",
    "\n",
    "                    double bonus = 0.0;\n",
    "                    if (!doc['averageReviewScore'].empty) {\n",
    "                        double r = Math.min(Math.max(doc['averageReviewScore'].value, 0.0), 5.0);\n",
    "                        bonus += (r / 5.0) * 0.5;\n",
    "                    }\n",
    "                    if (!doc['totalReviewCount'].empty) {\n",
    "                        double n = Math.min(doc['totalReviewCount'].value, 5000);\n",
    "                        bonus += (n / 5000.0) * 0.5;\n",
    "                    }\n",
    "\n",
    "                    return 1.0 + 5.0 * sim + bonus;\n",
    "                \"\"\",\n",
    "                \"params\": {\n",
    "                    \"qvec\": query_vec\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    if pos_ings:\n",
    "        functions.append({\n",
    "            \"filter\": _ing_filter(list(pos_ings)),\n",
    "            \"weight\": 3.0\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"function_score\": {\n",
    "                \"query\": {\"term\": {\"category\": category}},\n",
    "                \"score_mode\": \"sum\",\n",
    "                \"boost_mode\": \"sum\",\n",
    "                \"functions\": functions\n",
    "            }\n",
    "        },\n",
    "        \"_source\": {\n",
    "            \"includes\": [\n",
    "                \"product_id\", \"productName\", \"brand\", \"category\",\n",
    "                \"ingredients\", \"salePrice\", \"averageReviewScore\",\n",
    "                \"totalReviewCount\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def search_candidates_per_category(es: Elasticsearch, fusion: Dict[str, Any], per_cat: int = 30):\n",
    "    query_vec = encode_query_from_fusion(fusion)\n",
    "    out: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for cat in CATEGORIES:\n",
    "        body = build_query(fusion, cat, per_cat, query_vec)\n",
    "        resp = es.search(index=INDEX_NAME, body=body)\n",
    "        hits = resp.get(\"hits\", {}).get(\"hits\", [])\n",
    "        out[cat] = [\n",
    "            {\n",
    "                \"rank_es\": i + 1,\n",
    "                \"score_es\": h[\"_score\"],\n",
    "                **h[\"_source\"],\n",
    "            }\n",
    "            for i, h in enumerate(hits)\n",
    "        ]\n",
    "    return out\n",
    "\n",
    "\n",
    "def _make_pos_neg_vocab(fusion: Dict[str, Any]) -> Tuple[set, set]:\n",
    "    idx = fusion.get(\"indices\", {})\n",
    "    oil = float(idx.get(\"oil\", 0.0))\n",
    "    dry = float(idx.get(\"dry\", 0.0))\n",
    "    sens = float(idx.get(\"sensitivity\", 0.0))\n",
    "    pigment = float(idx.get(\"pigment\", 0.0))\n",
    "    acne = 1.0 if fusion.get(\"flags\", {}).get(\"acne\") else 0.0\n",
    "    pos, neg = set(), set()\n",
    "    if pigment >= 2.0:\n",
    "        pos |= POS_ING[\"pigment\"]\n",
    "    if sens >= 2.0:\n",
    "        pos |= POS_ING[\"sensitivity\"]\n",
    "        neg |= NEG_ING[\"sensitivity\"]\n",
    "    if dry >= 2.0:\n",
    "        pos |= POS_ING[\"dry\"]\n",
    "    if oil >= 2.0 or acne:\n",
    "        pos |= POS_ING[\"acne\"]\n",
    "        neg |= NEG_ING[\"acne\"]\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "def _ingredients_hits(ingredients, vocab):\n",
    "    return sum(1 for x in (ingredients or []) if x in vocab)\n",
    "\n",
    "\n",
    "def _safe_log1p(x):\n",
    "    try:\n",
    "        return math.log1p(float(x)) if x else 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def featurize(results_by_cat: Dict[str, List[Dict[str, Any]]], fusion: Dict[str, Any]):\n",
    "    pos_vocab, neg_vocab = _make_pos_neg_vocab(fusion)\n",
    "    X, group, ids, cats = [], [], [], []\n",
    "\n",
    "    for cat in CATEGORIES:\n",
    "        rows = results_by_cat.get(cat, [])\n",
    "        group.append(len(rows))\n",
    "\n",
    "        for r in rows:\n",
    "            ingredients = r.get(\"ingredients\") or []\n",
    "            pos_hits = _ingredients_hits(ingredients, pos_vocab)\n",
    "            neg_hits = _ingredients_hits(ingredients, neg_vocab)\n",
    "            pos_ratio = (pos_hits / max(1, len(ingredients))) if ingredients else 0.0\n",
    "\n",
    "            avg = r.get(\"averageReviewScore\")\n",
    "            cnt = r.get(\"totalReviewCount\")\n",
    "            price = r.get(\"salePrice\")\n",
    "            es_score = r.get(\"score_es\", 0.0)\n",
    "\n",
    "            X.append(\n",
    "                [\n",
    "                    pos_hits,\n",
    "                    neg_hits,\n",
    "                    pos_hits - neg_hits,\n",
    "                    pos_ratio,\n",
    "                    avg or 0.0,\n",
    "                    _safe_log1p(cnt),\n",
    "                    _safe_log1p(price),\n",
    "                    es_score,\n",
    "                ]\n",
    "            )\n",
    "            ids.append(r[\"product_id\"])\n",
    "            cats.append(cat)\n",
    "\n",
    "    return X, group, ids, cats\n",
    "\n",
    "\n",
    "def load_booster(model_path: str = LTR_MODEL_PATH):\n",
    "    import xgboost as xgb\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(model_path)\n",
    "    return booster\n",
    "\n",
    "\n",
    "def rerank_with_booster(results_by_cat, fusion, booster):\n",
    "    import xgboost as xgb\n",
    "    X, group, ids, cats = featurize(results_by_cat, fusion)\n",
    "    if not X:\n",
    "        return {c: [] for c in CATEGORIES}\n",
    "\n",
    "    X_arr = np.asarray(X, dtype=np.float32)\n",
    "    dmat = xgb.DMatrix(X_arr)\n",
    "    preds = booster.predict(dmat)\n",
    "\n",
    "    out = {c: [] for c in CATEGORIES}\n",
    "    idx = 0\n",
    "    for cat in CATEGORIES:\n",
    "        rows = results_by_cat.get(cat, [])\n",
    "        n = len(rows)\n",
    "        for i in range(n):\n",
    "            row = dict(rows[i])\n",
    "            row[\"score_ltr\"] = float(preds[idx + i])\n",
    "            out[cat].append(row)\n",
    "        out[cat].sort(key=lambda r: r[\"score_ltr\"], reverse=True)\n",
    "        for rank, r in enumerate(out[cat], 1):\n",
    "            r[\"rank_ltr\"] = rank\n",
    "        idx += n\n",
    "    return out\n",
    "\n",
    "\n",
    "def top_k_overall(reranked_by_cat, k=3):\n",
    "    merged = [dict(r, category=c) for c, rows in reranked_by_cat.items() for r in rows]\n",
    "    merged.sort(key=lambda x: x.get(\"score_ltr\", 0.0), reverse=True)\n",
    "    return merged[:k]\n",
    "\n",
    "\n",
    "def top_k_per_category(reranked_by_cat, k=3):\n",
    "    return {c: rows[:k] for c, rows in reranked_by_cat.items()}\n",
    "\n",
    "\n",
    "def recommend_from_fusion_online(es: Elasticsearch, booster, fusion_json: Dict[str, Any], topk: int = 3):\n",
    "    es_results = search_candidates_per_category(es, fusion_json, per_cat=30)\n",
    "    reranked = rerank_with_booster(es_results, fusion_json, booster)\n",
    "\n",
    "    all_items = []\n",
    "    for cat, items in reranked.items():\n",
    "        for doc in items:\n",
    "            all_items.append(doc)\n",
    "    all_items.sort(key=lambda d: d.get(\"score_ltr\", 0.0), reverse=True)\n",
    "\n",
    "    return all_items[:topk]\n",
    "\n",
    "\n",
    "es_global = connect_es()\n",
    "booster_global = load_booster(LTR_MODEL_PATH)\n",
    "\n",
    "\n",
    "def recommend_for_request(fusion_json: Dict[str, Any], topk: int = 3):\n",
    "    return recommend_from_fusion_online(es_global, booster_global, fusion_json, topk=topk)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fusion_json = {\n",
    "        \"skin_type\": \"복합성\",\n",
    "        \"indices\": {\n",
    "            \"oil\": 2.2,\n",
    "            \"dry\": 1.0,\n",
    "            \"sensitivity\": 2.4,\n",
    "            \"wrinkle\": 1.2,\n",
    "            \"pigment\": 2.8,\n",
    "        },\n",
    "        \"flags\": {\"sensitive\": True, \"aging\": False, \"pigment\": True, \"acne\": False},\n",
    "    }\n",
    "\n",
    "    es = es_global\n",
    "    booster = booster_global\n",
    "\n",
    "    es_results = search_candidates_per_category(es, fusion_json, per_cat=15)\n",
    "\n",
    "    for cat in CATEGORIES:\n",
    "        print(f\"\\n--- {cat.upper()} (ES candidates) ---\")\n",
    "        for r in es_results.get(cat, []):\n",
    "            print(\n",
    "                f\"- ({r['score_es']:.4f}) {r.get('brand','')} | \"\n",
    "                f\"{r.get('productName','')[:80]} | {r.get('salePrice')}\"\n",
    "            )\n",
    "\n",
    "    reranked = rerank_with_booster(es_results, fusion_json, booster)\n",
    "\n",
    "    print(\"\\n===  CATEGORY TOP-3 (after LTR) ===\")\n",
    "    top3_by_cat = top_k_per_category(reranked, 3)\n",
    "    for cat, rows in top3_by_cat.items():\n",
    "        print(f\"\\n[{cat.upper()}]\")\n",
    "        for r in rows:\n",
    "            print(\n",
    "                f\"- (LTR:{r['score_ltr']:.4f} | ES:{r['score_es']:.4f}) \"\n",
    "                f\"{r.get('brand','')} | {r.get('productName','')[:80]} | {r.get('salePrice')}\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
