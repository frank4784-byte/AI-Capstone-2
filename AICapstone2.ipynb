{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ebda487-a45a-416c-ab97-b753397f261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 전처리 완료: 0001_01_F.jpg\n",
      "\n",
      "[Gemini 이미지 분석 결과]\n",
      "{\n",
      "  \"acne\": {\n",
      "    \"score\": 15.0,\n",
      "    \"reason\": \"Slight presence of small acne spots, mostly on the forehead and cheeks.\"\n",
      "  },\n",
      "  \"redness\": {\n",
      "    \"score\": 30.0,\n",
      "    \"reason\": \"Mild redness observed, particularly around the nose and cheek areas.\"\n",
      "  },\n",
      "  \"melasma_darkspots\": {\n",
      "    \"score\": 55.0,\n",
      "    \"reason\": \"Moderate presence of dark spots and melasma, especially on the cheeks and forehead.\"\n",
      "  }\n",
      "}\n",
      "\n",
      "[설문+이미지 융합 결과]\n",
      "{\n",
      "  \"skin_type\": \"중성\",\n",
      "  \"indices\": {\n",
      "    \"oil\": 1.53,\n",
      "    \"dry\": 1.0,\n",
      "    \"sensitivity\": 1.34,\n",
      "    \"wrinkle\": 1.0,\n",
      "    \"pigment\": 1.75\n",
      "  },\n",
      "  \"vision_raw\": {\n",
      "    \"acne\": {\n",
      "      \"score\": 15.0,\n",
      "      \"reason\": \"Slight presence of small acne spots, mostly on the forehead and cheeks.\"\n",
      "    },\n",
      "    \"redness\": {\n",
      "      \"score\": 30.0,\n",
      "      \"reason\": \"Mild redness observed, particularly around the nose and cheek areas.\"\n",
      "    },\n",
      "    \"melasma_darkspots\": {\n",
      "      \"score\": 55.0,\n",
      "      \"reason\": \"Moderate presence of dark spots and melasma, especially on the cheeks and forehead.\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os, json, mimetypes, argparse\n",
    "import cv2, numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from typing import Dict, Tuple, Union\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "TARGET_SHORT = 768\n",
    "\n",
    "def _load_exif_bgr(path: str):\n",
    "    pil = Image.open(path)\n",
    "    pil = ImageOps.exif_transpose(pil).convert(\"RGB\")\n",
    "    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def _resize_short(bgr, short=TARGET_SHORT):\n",
    "    h, w = bgr.shape[:2]\n",
    "    s = min(h, w)\n",
    "    if s == short: return bgr\n",
    "    scale = short / float(s)\n",
    "    new = (int(round(w * scale)), int(round(h * scale)))\n",
    "    interp = cv2.INTER_AREA if scale < 1.0 else cv2.INTER_CUBIC\n",
    "    return cv2.resize(bgr, new, interpolation=interp)\n",
    "\n",
    "def _wb_grayworld(bgr, strength=0.5):\n",
    "    x = bgr.astype(np.float32)\n",
    "    means = x.reshape(-1,3).mean(0) + 1e-6\n",
    "    g = means.mean()\n",
    "    gains = np.clip(g/means, 0.8, 1.2)\n",
    "    gains = (1-strength)*1.0 + strength*gains\n",
    "    x *= gains\n",
    "    return np.clip(x, 0, 255).astype(np.uint8)\n",
    "\n",
    "def _clahe_light(bgr, clip=1.8, tiles=8):\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = cv2.createCLAHE(clipLimit=clip, tileGridSize=(tiles, tiles)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def _skin_mask(bgr):\n",
    "    ycrcb = cv2.cvtColor(bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    Y, Cr, Cb = cv2.split(ycrcb)\n",
    "    m1 = (Cr >= 135) & (Cr <= 180) & (Cb >= 85) & (Cb <= 135) & (Y >= 40) & (Y <= 240)\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "    m2 = (H <= 25) & (S >= 30) & (S <= 180) & (V >= 60)\n",
    "    m = (m1 & m2).astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN,  k, iterations=1)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, k, iterations=2)\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(m, connectivity=8)\n",
    "    if num > 1:\n",
    "        largest = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "        m2 = np.zeros_like(m)\n",
    "        m2[labels == largest] = 255\n",
    "        m = m2\n",
    "    return m\n",
    "\n",
    "def preprocess_with_mask(bgr, bg_gray=220):\n",
    "    bgr = _resize_short(bgr)\n",
    "    bgr = _wb_grayworld(bgr, 0.5)\n",
    "    bgr = _clahe_light(bgr, 1.8, 8)\n",
    "    mask = _skin_mask(bgr)\n",
    "    bg = np.full_like(bgr, (bg_gray, bg_gray, bg_gray), np.uint8)\n",
    "    out = np.where(mask[..., None] == 255, bgr, bg)\n",
    "    return out\n",
    "\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "PROMPT_TEXT = (\n",
    "    \"전처리된 얼굴 피부 이미지를 분석하여 JSON만 반환하라.\\n\"\n",
    "    \"평가 항목: acne(여드름), redness(홍조), melasma_darkspots(잡티).\\n\"\n",
    "    \"각 항목은 다음 스키마로 제공하라:\\n\"\n",
    "    \"{acne:{score:number,reason:string}, redness:{score:number,reason:string}, \"\n",
    "    \"melasma_darkspots:{score:number,reason:string}}\\n\"\n",
    "    \"score는 0~100 범위의 실수이며, 0은 없음·매우 양호, 100은 매우 심함을 의미한다.\"\n",
    ")\n",
    "\n",
    "def analyze_with_gemini(image_path, api_key):\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    mime = mimetypes.guess_type(image_path)[0] or \"image/jpeg\"\n",
    "    with open(image_path, \"rb\") as f: img_bytes = f.read()\n",
    "    content = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "            types.Part(text=PROMPT_TEXT),\n",
    "            types.Part(inline_data=types.Blob(mime_type=mime, data=img_bytes)),\n",
    "        ],\n",
    "    )\n",
    "    resp = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[content],\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            temperature=0.2,\n",
    "            system_instruction=\"너는 피부 분석 전문가다. 반드시 JSON만 반환하라.\"\n",
    "        ),\n",
    "    )\n",
    "    txt = (resp.text or \"\").strip()\n",
    "    start, end = txt.find(\"{\"), txt.rfind(\"}\")\n",
    "    return json.loads(txt[start:end+1]) if start != -1 else {}\n",
    "\n",
    "\n",
    "MAP = {\n",
    "    \"q1\": {\"없어요\":0,\"T존 일부(이마 혹은 코)\":1,\"T존 전체(이마와 코)\":2,\"얼굴 전체\":3},\n",
    "    \"q2\": {\"전혀 안 보여요\":0,\"지금은 없지만 가끔 보여요\":1,\"부분적으로 붉게 보여요\":2,\"전체적으로 붉게 보여요\":3},\n",
    "    \"q3\": {\"없어요\":0,\"U존 일부(볼 혹은 턱)\":1,\"U존 전체(볼과 턱)\":2,\"얼굴 전체\":3},\n",
    "    \"q4\": {\"전혀 생기지 않아요\":0,\"표정을 지을 때만 생겨요\":1,\"표정 짓지 않아도 약간 있어요\":2,\"표정 짓지 않아도 많이 있어요\":3},\n",
    "    \"q5\": {\"주름이 없어요\":0,\"잔주름이에요\":1,\"깊은 주름이에요\":2,\"잔주름과 깊은 주름 다 있어요\":3},\n",
    "    \"q6\": {\"전혀 생기지 않아요\":0,\"미소 지을 때만 약간 생겨요\":1,\"미소 지을 때 진하게 생겨요\":2,\"미소 짓지 않아도 생겨요\":3},\n",
    "    \"q7\": {\"전혀 안 보여요\":0,\"거의 안 보여요\":1,\"약간 눈에 띄어요\":2,\"곳곳에 많이 보여요\":3},\n",
    "    \"q8\": {\"주름이 없어요\":0,\"잔주름이에요\":1,\"깊은 주름이에요\":2,\"잔주름과 깊은 주름 다 있어요\":3},\n",
    "    \"q9\": {\"외출 전보다 윤기가 없어요\":0,\"외출 전과 변함이 없어요\":1,\"약간 번들거리고 윤기가 있어요\":2,\"많이 번들거리고 기름져요\":3}\n",
    "}\n",
    "\n",
    "def _to_score(q, v): return MAP[q].get(v, 0)\n",
    "def _to_0_3(x): return round(max(0, min(100, float(x))) / 100 * 3, 2)\n",
    "\n",
    "def assess_skin_type(**a):\n",
    "    s = {k:_to_score(k,v) for k,v in a.items()}\n",
    "    oil = round(0.6*s[\"q1\"] + 0.4*s[\"q9\"],2)\n",
    "    dry = float(s[\"q3\"]); sens=float(s[\"q2\"])\n",
    "    wrinkle=round(0.4*s[\"q4\"] + 0.6*((s[\"q5\"]+s[\"q8\"])/2),2)\n",
    "    pigment=float(s[\"q7\"])\n",
    "    if oil>=2 and dry<=1: skin=\"지성\"\n",
    "    elif dry>=2 and oil<=1: skin=\"건성\"\n",
    "    elif oil>=2 and dry>=2: skin=\"복합성\"\n",
    "    else: skin=\"중성\"\n",
    "    return {\"skin_type\":skin,\"indices\":{\"oil\":oil,\"dry\":dry,\"sensitivity\":sens,\"wrinkle\":wrinkle,\"pigment\":pigment}}\n",
    "\n",
    "def assess_with_gemini(survey, gemini):\n",
    "    base=assess_skin_type(**survey)\n",
    "    idx=base[\"indices\"]; fused=idx.copy()\n",
    "    acne,red,mel=[_to_0_3(gemini[k][\"score\"]) for k in [\"acne\",\"redness\",\"melasma_darkspots\"]]\n",
    "    fused[\"sensitivity\"]=round(0.4*idx[\"sensitivity\"]+0.6*red,2)\n",
    "    fused[\"pigment\"]=round(0.3*idx[\"pigment\"]+0.7*mel,2)\n",
    "    fused[\"oil\"]=round(0.7*idx[\"oil\"]+0.3*acne,2)\n",
    "    fused[\"dry\"]=idx[\"dry\"]; fused[\"wrinkle\"]=idx[\"wrinkle\"]\n",
    "    if fused[\"oil\"]>=2 and fused[\"dry\"]<=1: skin=\"지성\"\n",
    "    elif fused[\"dry\"]>=2 and fused[\"oil\"]<=1: skin=\"건성\"\n",
    "    elif fused[\"oil\"]>=2 and fused[\"dry\"]>=2: skin=\"복합성\"\n",
    "    else: skin=\"중성\"\n",
    "    return {\"skin_type\":skin,\"indices\":fused,\"vision_raw\":gemini}\n",
    "\n",
    "def run_full_pipeline(input_path, survey_json):\n",
    "    original=_load_exif_bgr(input_path)\n",
    "    processed=preprocess_with_mask(original)\n",
    "    pre_path=input_path.replace(\".jpeg\",\"_Pre.jpg\")\n",
    "    cv2.imwrite(pre_path,processed)\n",
    "    print(f\"[INFO] 전처리 완료: {pre_path}\")\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "    gemini=analyze_with_gemini(pre_path, api_key)\n",
    "    with open(survey_json,\"r\",encoding=\"utf-8\") as f: survey=json.load(f)\n",
    "    fused=assess_with_gemini(survey, gemini)\n",
    "    print(\"\\n[Gemini 이미지 분석 결과]\"); print(json.dumps(gemini,ensure_ascii=False,indent=2))\n",
    "    print(\"\\n[설문+이미지 융합 결과]\"); print(json.dumps(fused,ensure_ascii=False,indent=2))\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    run_full_pipeline(\"0001_01_F.jpg\",\"survey_example.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fc9d94-452e-4b5f-8f92-91920effd6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] indexed: 243 docs\n",
      "\n",
      "=== CREAM (ES candidates) ===\n",
      "- (1.5) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 EDLP 어성초 71% 수분크림(대용량) 120g /수분진정 속건조개선 민감지성피부 촘촘보습 2배용량 수분만땅 | 7000\n",
      "- (1.499) 한율 | [본사직영] 한율 어린쑥 수분진정크림 55ml /한율 1등템 | 27580\n",
      "- (1.499) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 비제로 컴포트 크림 80ml / 마일드크림 장벽보호 진정보습 온가족크림 자극지수 0.00 민감피부 구아이아줄렌 덱스판테놀 5% | 7800\n",
      "- (1.498) 달바 공식스토어 | 달바 비건 더블 크림 단지형 70g | 37900\n",
      "- (1.498) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 아쿠아포린 수분 크림 70ml /글리세릴글루코사이드 부활초 수분길활성 초저분자히알루론산 갈바닉크림 속수분크림 스쿠알란 오일프리 수분젤크림 | 7000\n",
      "- (1.498) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 EDLP 어성초 71% 수분크림 60g /속건조개선 민감지성피부 열감감소 수분가득 촉촉크림 | 4500\n",
      "- (1.495) 달바 공식스토어 | 달바 비건 더블 크림 튜브형 60ml | 29900\n",
      "- (1.495) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 세라판테놀 8% 인텐시브 크림 (세라마이드 10,000ppm) 50ml /고보습크림 보습영양 탄력크림 속보습 장벽케어크림 판테놀크림 스쿠알란10% 판테놀7% | 9000\n",
      "- (1.495) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 시카53.2%크림 30ml / 마데카소사이드 센텔라정량추출물(TECA) 1.1% 병풀잎수 트러블진정 장벽케어 민감피부진정 급속진정 | 9000\n",
      "- (1.493) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 레티날 300ppm 크림 30ml /비타민 A 레티날 레티놀 리프팅 주름개선 크림 | 9000\n",
      "- (1.493) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 바쿠치올 10,000ppm(1%) 크림 30g / 주름개선 모공 탄력크림 | 8000\n",
      "- (1.492) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 레티날 1000ppm 크림 30ml /비타민A 레티날 레티놀 모공탄력 깐달걀피부 리프팅 미백 주름개선 레틴A 탄력세럼 포르테 초고함량 레티노이드 | 15000\n",
      "- (1.49) 달바 공식스토어 | 달바 비건 멀티밤 10g | 19900\n",
      "- (1.49) 마몽드 | [싱글] 마몽드 포어 슈링커 바쿠치올 크림 60ml x 1개 | 28500\n",
      "- (1.49) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 트라넥삼산(트라넥사믹애씨드) 6%크림 30ml /미백 기미크림 화이트닝 멜라닌 잡티크림 밝은피부 투명피부 미백기능성 다크스팟케어 | 8000\n",
      "\n",
      "=== ESSENSE (ES candidates) ===\n",
      "- (13.754) 보나쥬르 | 보나쥬르 비건 부활초 에센스 / 수분 미백 탄력 글리세릴글루코사이드 화장품 50ml | 27700\n",
      "- (6.398) 닥터트웬티프로젝트 | 수분진정 나인세럼 (9세럼) 50ml | 28000\n",
      "- (1.266) 토리든 | [2종세트]토리든 다이브인 히알루론산 세럼 50ml+40ml +(다이브인 멀티패드 2매입x2개) | 28000\n",
      "- (1.266) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 EDLP 어성초 89% 세럼 50ml /보습충전 진정효과 민감지성피부 트러블진정부스터 끈적임제로 산뜻세럼 | 4500\n",
      "- (1.266) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 히알루론 1% 세럼 (히알루론산 1% 세럼) 80ml / 고순도히알루론 大용량 수분보습 산뜻촉촉 속보습세럼 | 11000\n",
      "- (1.266) 스킨푸드 | [스킨푸드][마스크 5매+크림 미니 증정] 캐롯 카로틴 모이스트 진정 수분 앰플 이펙터 55m_당근앰플 | 15000\n",
      "- (1.265) 이니스프리 | 이니스프리 그린티 씨드 히알루론산 수분세럼 / 진정 보습 속건조 화잘먹 | 46500\n",
      "- (1.265) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 아데노신 7500ppm 워터에센스 150ml / 탄력케어 보습영양 퍼스트에센스 수분광채 탄력스킨 콜라겐스킨 영양공급 | 10000\n",
      "- (1.264) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 시카 90% 워터 에센스 150ml/진정보습 장벽케어 산뜻토너 시카에센스 진정에센스 시카토너 진정토너 수분진정 병풀토너 손상케어 | 10000\n",
      "- (1.264) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 나이아신 히알루론 21%세럼 (나이아신아마이드 + 히알루론산) 80ml /초저분자히알루론산 수분충전 수분생기 다마스크장미꽃수 | 15000\n",
      "- (1.263) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 나이아신아마이드 20%(200,000ppm) 세럼 한글에디션 80ml/모공세럼 브라이트닝 모공탄력 결케어 맑은피부케어 비타민B3 | 11200\n",
      "- (1.262) 더마팩토리 온라인스토어 | [비건인증] (비타민 C 15%) 더마팩토리 퓨어 비타민 C E 페룰릭 앰플 22ml / 미백앰플 화이트닝 톤업케어 생기케어 칙칙한피부 멀티앰플 순수비타민C 고함량비타민C | 10000\n",
      "- (1.262) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 리얼베라 모공세럼 30ml /모공케어 가로모공 세로모공 모공타이트닝 블랙헤드 모공탄력 모공축소 | 8000\n",
      "- (1.261) 달바 공식스토어 | 달바 비건 더블 세럼 30ml | 28900\n",
      "- (1.261) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 나이아신아마이드 20%(200,000ppm) 세럼 30ml /모공세럼 브라이트닝 모공탄력 모공쫀쫀 결케어 맑은피부케어 비타민B3 비타민세럼 | 6000\n",
      "\n",
      "=== SKINTONER (ES candidates) ===\n",
      "- (14.885) 보나쥬르 | 보나쥬르 가지 데일리 BHA 토너 / 비건인증 바하 약산성 각질토너 205ml | 16200\n",
      "- (8.038) 아모레퍼시픽몰 헤어바디 | 일리윤 세라마이드 아토 속보습 스킨 250ml | 18400\n",
      "- (2.533) 마몽드 | [싱글] 마몽드 플로라 글로우 로즈 워터 토너 500ml x 1개 | 17500\n",
      "- (2.529) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 EDLP 어성초 84% 에센스 토너 300ml /수분공급 진정보습 민감지성피부 열감감소 트러블진정 산뜻토너 | 5500\n",
      "- (2.526) 이니스프리 | 이니스프리 그린티 히알루론산 스킨 / 저자극 수부지 속건조 170ml, 3개 | 39900\n",
      "- (2.513) 디어클레어스 | 클레어스 서플 프레퍼레이션 페이셜 에센스 토너 180ml / 속건조 수분 보습 진정 | 13900\n",
      "- (2.502) 싸이닉 공식스토어 | 싸이닉 더 심플 비건 카밍 토너 145ml / 비건 수부지 진정 토너 | 11250\n",
      "- (2.493) 에센허브 공식몰 | 에센허브 비건 티트리 카밍토너320ml | 19950\n",
      "- (2.486) 한율 | [본사직영] 한율 어린쑥 수분진정 토너 150ml | 20790\n",
      "- (2.367) 싸이닉 공식스토어 | [초대용량/1+1] 싸이닉 더 심플 비건 카밍 토너 대용량 500ml / 비건 수부지 진정 토너 | 23500\n",
      "- (2.344) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 데일리 모공 토너 150ml / 수분필링 결케어 피지연화토너 블랙헤드 화이트헤드 피부광채 AHA BHA PHA LHA 각질케어 지복합성피부 | 9000\n",
      "- (2.314) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 글루코노락톤(PHA) 10% 트리트먼트 150ml /데일리필링 순한각질토너 촉촉필링 PHA 10% 피부턴오버 자작나무수액 저자극필링 건성피부필링 | 9000\n",
      "- (2.286) 디어클레어스 | 클레어스 서플 프레퍼레이션 언센티드 에센스 토너 180ml / 속건조 수분 보습 진정 | 13900\n",
      "- (2.244) 더마팩토리 온라인스토어 | [비건인증] 더마팩토리 비제로 마일드 토너 250ml / n스킨 n겹토너 자극지수 0.00 저자극 민감피부 물토너 수분보습 흡토 닦토 토너팩 덱스판테놀 1% | 6800\n",
      "- (2.226) 토니모리 공식몰 | 토니모리 원더 비건 라벨 세라마이드 모찌 진정 토너 500ml | 17820\n"
     ]
    }
   ],
   "source": [
    "import json, os, hashlib, re\n",
    "from typing import List, Dict, Any, Iterable\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "def connect_es():\n",
    "    return Elasticsearch(\"http://localhost:9201\", request_timeout=20)\n",
    "\n",
    "INDEX_NAME = \"cosmetics_demo\"\n",
    "\n",
    "def load_json(path: str) -> List[Dict[str, Any]]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def normalize_product(doc: Dict[str, Any], category: str) -> Dict[str, Any]:\n",
    "    name = doc.get(\"productName\") or \"\"\n",
    "    brand = doc.get(\"mallName\") or \"\"\n",
    "    price = doc.get(\"salePrice\")\n",
    "    price_disc = doc.get(\"discountedSalePrice\")\n",
    "    avg_score = doc.get(\"averageReviewScore\")\n",
    "    review_cnt = doc.get(\"totalReviewCount\")\n",
    "\n",
    "    ing_str = (doc.get(\"ingredientsInfo\") or {}).get(\"ingredients\")\n",
    "    if isinstance(ing_str, str):\n",
    "        ingredients = [s.strip().lower() for s in ing_str.split(\",\") if s.strip()]\n",
    "    else:\n",
    "        ingredients = []\n",
    "\n",
    "    reviews = doc.get(\"reviews\") or []\n",
    "    review_text = \" \".join([str(r.get(\"reviewContent\", \"\")) for r in reviews])[:5000]  # 길이 제한\n",
    "\n",
    "    pid = hashlib.md5(f\"{name}|{brand}\".encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    return {\n",
    "        \"product_id\": pid,\n",
    "        \"productName\": name,\n",
    "        \"brand\": brand,\n",
    "        \"category\": category,               \n",
    "        \"ingredients\": ingredients,         \n",
    "        \"review_text\": review_text,         \n",
    "        \"salePrice\": price,\n",
    "        \"discountedSalePrice\": price_disc,\n",
    "        \"averageReviewScore\": avg_score,\n",
    "        \"totalReviewCount\": review_cnt,\n",
    "    }\n",
    "\n",
    "def load_and_normalize_all() -> List[Dict[str, Any]]:\n",
    "    base = os.getcwd()\n",
    "    files = [\n",
    "        (\"cream.json\", \"cream\"),\n",
    "        (\"essense.json\", \"essense\"),      \n",
    "        (\"skintoner.json\", \"skintoner\"),  \n",
    "    ]\n",
    "    out = []\n",
    "    for fname, cat in files:\n",
    "        path = os.path.join(base, fname)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"[WARN] not found: {path}\")\n",
    "            continue\n",
    "        raw = load_json(path)\n",
    "        for doc in raw:\n",
    "            out.append(normalize_product(doc, cat))\n",
    "    return out\n",
    "\n",
    "\n",
    "MAPPING = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"ko_std\": {\"tokenizer\": \"standard\", \"filter\": [\"lowercase\"]}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"product_id\": {\"type\": \"keyword\"},\n",
    "            \"productName\": {\"type\": \"text\", \"analyzer\": \"ko_std\"},\n",
    "            \"brand\": {\"type\": \"keyword\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"ingredients\": {\"type\": \"keyword\"},           \n",
    "            \"review_text\": {\"type\": \"text\", \"analyzer\": \"ko_std\"},\n",
    "            \"salePrice\": {\"type\": \"float\"},\n",
    "            \"discountedSalePrice\": {\"type\": \"float\"},\n",
    "            \"averageReviewScore\": {\"type\": \"float\"},\n",
    "            \"totalReviewCount\": {\"type\": \"integer\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def ensure_index(es: Elasticsearch):\n",
    "    if es.indices.exists(index=INDEX_NAME):\n",
    "        return\n",
    "    es.indices.create(index=INDEX_NAME, **MAPPING)\n",
    "\n",
    "def bulk_index(es: Elasticsearch, docs: List[Dict[str, Any]]):\n",
    "    ops = []\n",
    "    for d in docs:\n",
    "        ops.append({\"_op_type\": \"index\", \"_index\": INDEX_NAME, \"_id\": d[\"product_id\"], \"_source\": d})\n",
    "    if ops:\n",
    "        helpers.bulk(es, ops, refresh=\"wait_for\")\n",
    "\n",
    "\n",
    "POS_ING = {\n",
    "    \"pigment\": {\"niacinamide\",\"vitamin c\",\"ascorbic\",\"3-o-ethyl ascorbic\",\"arbutin\",\"alpha arbutin\",\"tranexamic\",\"licorice\",\"kojic\"},\n",
    "    \"sensitivity\": {\"panthenol\",\"madecassoside\",\"centella\",\"cica\",\"allantoin\",\"beta-glucan\",\"bisabolol\",\"aloe\",\"ceramide\"},\n",
    "    \"dry\": {\"hyaluronic\",\"glycerin\",\"squalane\",\"ceramide\",\"cholesterol\",\"urea\"},\n",
    "    \"acne\": {\"salicylic\",\"bha\",\"lipo-hydroxy\",\"azelaic\",\"zinc\",\"niacinamide\"},\n",
    "}\n",
    "\n",
    "NEG_ING = {\n",
    "    \"sensitivity\": {\"fragrance\",\"parfum\",\"linalool\",\"limonene\",\"citral\",\"eugenol\",\"essential oil\",\"tea tree oil\",\"peppermint oil\",\"alcohol denat\"},\n",
    "    \"acne\": {\"coconut oil\",\"isopropyl myristate\",\"lanolin\",\"myristyl myristate\"},\n",
    "}\n",
    "\n",
    "def build_query(fusion: Dict[str, Any], category: str, top_k: int = 15) -> Dict[str, Any]:\n",
    "    idx = fusion.get(\"indices\", {})\n",
    "    oil = float(idx.get(\"oil\", 0))\n",
    "    dry = float(idx.get(\"dry\", 0))\n",
    "    sens = float(idx.get(\"sensitivity\", 0))\n",
    "    pigment = float(idx.get(\"pigment\", 0))\n",
    "    acne_flag = 1.0 if fusion.get(\"flags\", {}).get(\"acne\") else 0.0\n",
    "\n",
    "    pos_ings = set()\n",
    "    neg_ings = set()\n",
    "    if pigment >= 2.0: pos_ings |= POS_ING[\"pigment\"]\n",
    "    if sens >= 2.0:    pos_ings |= POS_ING[\"sensitivity\"]; neg_ings |= NEG_ING[\"sensitivity\"]\n",
    "    if dry >= 2.0:     pos_ings |= POS_ING[\"dry\"]\n",
    "    if oil >= 2.0 or acne_flag: pos_ings |= POS_ING[\"acne\"]; neg_ings |= NEG_ING[\"acne\"]\n",
    "\n",
    "    functions = [\n",
    "      \n",
    "        *([{\"filter\": {\"terms\": {\"ingredients\": list(pos_ings)}}, \"weight\": 1.5}] if pos_ings else []),\n",
    "        *([{\"filter\": {\"terms\": {\"ingredients\": list(neg_ings)}}, \"weight\": 0.7}] if neg_ings else []),\n",
    "        \n",
    "        {\n",
    "            \"script_score\": {\n",
    "                \"script\": {\n",
    "                    \"source\": \"\"\"\n",
    "                        double s = 1.0;\n",
    "                        if (!doc['averageReviewScore'].empty) {\n",
    "                            s *= (0.9 + Math.min(Math.max(doc['averageReviewScore'].value, 0.0), 5.0) / 10.0);\n",
    "                        }\n",
    "                        if (!doc['totalReviewCount'].empty) {\n",
    "                            double n = Math.min(doc['totalReviewCount'].value, 5000);\n",
    "                            s *= (0.9 + (n/5000.0)*0.2);\n",
    "                        }\n",
    "                        return s;\n",
    "                    \"\"\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    body = {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"function_score\": {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [{\"term\": {\"category\": category}}],\n",
    "                        \"should\": [\n",
    "                            {\"multi_match\": {\n",
    "                                \"query\": \"brightening soothing barrier oil-free non-comedogenic\",\n",
    "                                \"fields\": [\"productName^2\", \"review_text\"]\n",
    "                            }}\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"boost_mode\": \"multiply\",\n",
    "                \"score_mode\": \"multiply\",\n",
    "                \"functions\": functions\n",
    "            }\n",
    "        },\n",
    "        \"_source\": {\n",
    "            \"includes\": [\n",
    "                \"product_id\",\"productName\",\"brand\",\"category\",\n",
    "                \"ingredients\",\"salePrice\",\"discountedSalePrice\",\n",
    "                \"averageReviewScore\",\"totalReviewCount\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    return body\n",
    "\n",
    "\n",
    "CATEGORIES = [\"cream\",\"essense\",\"skintoner\"] \n",
    "\n",
    "def search_candidates_per_category(es: Elasticsearch, fusion: Dict[str, Any], per_cat: int = 15) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    out = {}\n",
    "    for cat in CATEGORIES:\n",
    "        q = build_query(fusion, category=cat, top_k=per_cat)\n",
    "        resp = es.search(index=INDEX_NAME, body=q)\n",
    "        hits = resp[\"hits\"][\"hits\"]\n",
    "        out[cat] = [{\n",
    "            \"rank_es\": i+1,\n",
    "            \"score_es\": round(h[\"_score\"], 3),\n",
    "            **h[\"_source\"]\n",
    "        } for i, h in enumerate(hits)]\n",
    "    return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    es = connect_es()\n",
    "\n",
    "   \n",
    "    ensure_index(es)\n",
    "    docs = load_and_normalize_all()\n",
    "    if docs:\n",
    "        bulk_index(es, docs)\n",
    "        print(f\"[INFO] indexed: {len(docs)} docs\")\n",
    "\n",
    "    fusion_json = {\n",
    "        \"skin_type\": \"복합성\",\n",
    "        \"indices\": {\"oil\": 2.2, \"dry\": 1.0, \"sensitivity\": 2.4, \"wrinkle\": 1.2, \"pigment\": 2.8},\n",
    "        \"flags\": {\"sensitive\": True, \"aging\": False, \"pigment\": True, \"acne\": False}\n",
    "    }\n",
    "\n",
    "    results = search_candidates_per_category(es, fusion_json, per_cat=15)\n",
    "    for cat, arr in results.items():\n",
    "        print(f\"\\n=== {cat.upper()} (ES candidates) ===\")\n",
    "        for r in arr:   \n",
    "            print(f\"- ({r['score_es']}) {r['brand']} | {r['productName']} | {r['discountedSalePrice'] or r['salePrice']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37fc48d8-2fbb-4b9a-8aa1-83d55226e7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_7000\\26936128.py\", line 5, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\frank\\AppData\\Local\\Temp\\ipykernel_7000\\26936128.py\", line 5, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\frank\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m POSITIVE_BY_CONCERN \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpigment\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaims\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrightening\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdark-spot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtone-up\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     }\n\u001b[0;32m     31\u001b[0m }\n\u001b[0;32m     33\u001b[0m NEGATIVE_BY_CONCERN \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensitivity\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mingredients\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfragrance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparfum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinalool\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimonene\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcitral\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meugenol\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     }\n\u001b[0;32m     41\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Any, List, Iterable, Set, Tuple\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "POSITIVE_BY_CONCERN = {\n",
    "    \"pigment\": {\n",
    "        \"claims\": {\"brightening\", \"dark-spot\", \"tone-up\"},\n",
    "        \"ingredients\": {\"niacinamide\", \"vitamin c\", \"ascorbic\", \"3-o-ethyl ascorbic\",\n",
    "                        \"arbutin\", \"alpha arbutin\", \"tranexamic\", \"licorice\", \"glabridin\", \"kojic\"}\n",
    "    },\n",
    "    \"sensitivity\": {\n",
    "        \"claims\": {\"soothing\", \"calming\", \"barrier\", \"hypoallergenic\"},\n",
    "        \"ingredients\": {\"panthenol\", \"madecassoside\", \"centella\", \"cica\", \"allantoin\",\n",
    "                        \"beta-glucan\", \"bisabolol\", \"aloe\", \"ceramide\"}\n",
    "    },\n",
    "    \"acne_hint\": {\n",
    "        \"claims\": {\"anti-acne\", \"non-comedogenic\", \"sebum-control\"},\n",
    "        \"ingredients\": {\"salicylic\", \"bha\", \"lipo-hydroxy\", \"azelaic\", \"zinc\", \"niacinamide\"}\n",
    "    },\n",
    "    \"dry\": {\n",
    "        \"claims\": {\"hydrating\", \"moisturizing\", \"barrier\"},\n",
    "        \"ingredients\": {\"hyaluronic\", \"glycerin\", \"squalane\", \"ceramide\", \"cholesterol\", \"urea\"}\n",
    "    },\n",
    "    \"oil\": {\n",
    "        \"claims\": {\"oil-free\", \"sebum-control\", \"matte\"},\n",
    "        \"tags\": {\"oil-free\", \"lightweight\", \"gel-cream\", \"non-comedogenic\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "NEGATIVE_BY_CONCERN = {\n",
    "    \"sensitivity\": {\n",
    "        \"ingredients\": {\"fragrance\", \"parfum\", \"linalool\", \"limonene\", \"citral\", \"eugenol\",\n",
    "                        \"essential oil\", \"tea tree oil\", \"peppermint oil\", \"alcohol denat\"}\n",
    "    },\n",
    "    \"acne_hint\": {\n",
    "        \"ingredients\": {\"coconut oil\", \"isopropyl myristate\", \"lanolin\", \"myristyl myristate\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def _to_list(x) -> List[str]:\n",
    "    if x is None: return []\n",
    "    if isinstance(x, (list, tuple, set)): return [str(v).lower() for v in x]\n",
    "    return [str(x).lower()]\n",
    "\n",
    "def _safe_float(x, default=np.nan):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _count_intersection(a: Iterable[str], b: Set[str]) -> int:\n",
    "    return len(set([str(v).lower() for v in a]) & set([str(v).lower() for v in b]))\n",
    "\n",
    "def make_ltr_features(cands: List[Dict[str, Any]], fusion_json: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ES 후보(한 카테고리의 리스트)를 받아 LTR 입력용 피처 DataFrame 생성\n",
    "    - 문서 단위 피처 + 사용자/쿼리 컨텍스트 피처(fusion indices)\n",
    "    \"\"\"\n",
    "    idx = fusion_json.get(\"indices\", {})\n",
    "    oil = float(idx.get(\"oil\", 0)); dry = float(idx.get(\"dry\", 0))\n",
    "    sens = float(idx.get(\"sensitivity\", 0)); pigment = float(idx.get(\"pigment\", 0))\n",
    "    wrinkle = float(idx.get(\"wrinkle\", 0))\n",
    "    acne_flag = 1.0 if fusion_json.get(\"flags\", {}).get(\"acne\") else 0.0\n",
    "\n",
    "    rows = []\n",
    "    for doc in cands:\n",
    "        ingredients = _to_list(doc.get(\"ingredients\"))\n",
    "        claims = _to_list(doc.get(\"claims\"))\n",
    "        tags = _to_list(doc.get(\"tags\"))\n",
    "\n",
    "        \n",
    "        pos_ing_cnt = (\n",
    "            _count_intersection(ingredients, POSITIVE_BY_CONCERN[\"pigment\"][\"ingredients\"]) +\n",
    "            _count_intersection(ingredients, POSITIVE_BY_CONCERN[\"sensitivity\"][\"ingredients\"]) +\n",
    "            _count_intersection(ingredients, POSITIVE_BY_CONCERN[\"dry\"][\"ingredients\"]) +\n",
    "            _count_intersection(ingredients, POSITIVE_BY_CONCERN[\"acne_hint\"][\"ingredients\"])\n",
    "        )\n",
    "        pos_claim_cnt = (\n",
    "            _count_intersection(claims, POSITIVE_BY_CONCERN[\"pigment\"][\"claims\"]) +\n",
    "            _count_intersection(claims, POSITIVE_BY_CONCERN[\"sensitivity\"][\"claims\"]) +\n",
    "            _count_intersection(claims, POSITIVE_BY_CONCERN[\"dry\"][\"claims\"]) +\n",
    "            _count_intersection(claims, POSITIVE_BY_CONCERN[\"acne_hint\"][\"claims\"]) +\n",
    "            _count_intersection(claims, POSITIVE_BY_CONCERN[\"oil\"][\"claims\"])\n",
    "        )\n",
    "        pos_tag_cnt = _count_intersection(tags, POSITIVE_BY_CONCERN[\"oil\"].get(\"tags\", set()))\n",
    "\n",
    "        neg_ing_cnt = (\n",
    "            _count_intersection(ingredients, NEGATIVE_BY_CONCERN[\"sensitivity\"][\"ingredients\"]) +\n",
    "            _count_intersection(ingredients, NEGATIVE_BY_CONCERN[\"acne_hint\"][\"ingredients\"])\n",
    "        )\n",
    "\n",
    "        \n",
    "        has_oil_free = 1.0 if (\"oil-free\" in tags or \"oil-free\" in claims) else 0.0\n",
    "        has_noncomedogenic = 1.0 if (\"non-comedogenic\" in tags or \"non-comedogenic\" in claims) else 0.0\n",
    "        has_soothing = 1.0 if (\"soothing\" in claims or \"calming\" in claims) else 0.0\n",
    "        has_brightening = 1.0 if (\"brightening\" in claims or \"tone-up\" in claims or \"dark-spot\" in claims) else 0.0\n",
    "\n",
    "        \n",
    "        es_score = _safe_float(doc.get(\"score_es\"), default=np.nan)\n",
    "        price = _safe_float(doc.get(\"price\"), default=np.nan)\n",
    "        comedo = _safe_float(doc.get(\"comedogenic_rating\"), default=np.nan)\n",
    "        spf = _safe_float(doc.get(\"spf\"), default=0.0)\n",
    "\n",
    "        \n",
    "        price_log = np.log1p(price) if np.isfinite(price) else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \n",
    "            \"es_score\": es_score,\n",
    "            \"price_log\": price_log,\n",
    "            \"comedogenic\": comedo,\n",
    "            \"spf\": spf,\n",
    "            \"pos_ing_cnt\": float(pos_ing_cnt),\n",
    "            \"pos_claim_cnt\": float(pos_claim_cnt),\n",
    "            \"pos_tag_cnt\": float(pos_tag_cnt),\n",
    "            \"neg_ing_cnt\": float(neg_ing_cnt),\n",
    "            \"has_oil_free\": has_oil_free,\n",
    "            \"has_noncomedogenic\": has_noncomedogenic,\n",
    "            \"has_soothing\": has_soothing,\n",
    "            \"has_brightening\": has_brightening,\n",
    "\n",
    "            \n",
    "            \"q_oil\": oil,\n",
    "            \"q_dry\": dry,\n",
    "            \"q_sensitivity\": sens,\n",
    "            \"q_pigment\": pigment,\n",
    "            \"q_wrinkle\": wrinkle,\n",
    "            \"q_acne_flag\": acne_flag,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "DEFAULT_FEATURE_ORDER = [\n",
    "    \"es_score\",\"price_log\",\"comedogenic\",\"spf\",\n",
    "    \"pos_ing_cnt\",\"pos_claim_cnt\",\"pos_tag_cnt\",\"neg_ing_cnt\",\n",
    "    \"has_oil_free\",\"has_noncomedogenic\",\"has_soothing\",\"has_brightening\",\n",
    "    \"q_oil\",\"q_dry\",\"q_sensitivity\",\"q_pigment\",\"q_wrinkle\",\"q_acne_flag\"\n",
    "]\n",
    "\n",
    "def align_features(df: pd.DataFrame, feature_order: List[str] = None) -> pd.DataFrame:\n",
    "    cols = feature_order or DEFAULT_FEATURE_ORDER\n",
    "   \n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_xgb_model(model_path: str):\n",
    "    \"\"\"\n",
    "    - .json/.ubj: Booster로 로드\n",
    "    - .pkl/.pickle: sklearn API로 로드\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(model_path)[1].lower()\n",
    "    if ext in [\".json\", \".ubj\"]:\n",
    "        import xgboost as xgb\n",
    "        bst = xgb.Booster()\n",
    "        bst.load_model(model_path)\n",
    "        return (\"booster\", bst)\n",
    "    elif ext in [\".pkl\", \".pickle\"]:\n",
    "        import pickle\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "        return (\"sklearn\", model)\n",
    "    else:\n",
    "        raise ValueError(f\"지원하지 않는 모델 확장자: {ext}\")\n",
    "\n",
    "def predict_scores(df_feat: pd.DataFrame, model_spec) -> np.ndarray:\n",
    "    kind, model = model_spec\n",
    "    if kind == \"booster\":\n",
    "        import xgboost as xgb\n",
    "        dmat = xgb.DMatrix(df_feat.values, feature_names=list(df_feat.columns))\n",
    "        pred = model.predict(dmat)\n",
    "        return np.asarray(pred).reshape(-1)\n",
    "    else:  \n",
    "        pred = model.predict(df_feat.values)\n",
    "        return np.asarray(pred).reshape(-1)\n",
    "\n",
    "\n",
    "def rank_topn_per_category(\n",
    "    candidates_by_cat: Dict[str, List[Dict[str, Any]]],\n",
    "    fusion_json: Dict[str, Any],\n",
    "    model_path: str,\n",
    "    top_n: int = 3,\n",
    "    feature_order: List[str] = None\n",
    ") -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    반환:\n",
    "    {\n",
    "      \"skin\":  [Top-N dict...],\n",
    "      \"toner\": [Top-N dict...],\n",
    "      ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    model = load_xgb_model(model_path)\n",
    "    out = {}\n",
    "\n",
    "    for cat, cands in candidates_by_cat.items():\n",
    "        if not cands:\n",
    "            out[cat] = []\n",
    "            continue\n",
    "        df_feat = make_ltr_features(cands, fusion_json)\n",
    "        df_feat = align_features(df_feat, feature_order)\n",
    "\n",
    "        scores = predict_scores(df_feat, model)\n",
    "\n",
    "      \n",
    "        ranked = sorted(zip(cands, scores), key=lambda x: x[1], reverse=True)\n",
    "        topk = []\n",
    "        for item, sc in ranked[:top_n]:\n",
    "            item_out = dict(item)\n",
    "            item_out[\"score_ltr\"] = float(sc)\n",
    "            topk.append(item_out)\n",
    "        out[cat] = topk\n",
    "    return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    fusion_json = {\n",
    "        \"skin_type\": \"복합성\",\n",
    "        \"indices\": {\"oil\": 2.2, \"dry\": 1.0, \"sensitivity\": 2.4, \"wrinkle\": 1.5, \"pigment\": 2.8},\n",
    "        \"flags\": {\"sensitive\": True, \"aging\": False, \"pigment\": True, \"acne\": False}\n",
    "    }\n",
    "\n",
    "    # 3) 모델 경로\n",
    "    model_path = \"models/ltr_model.json\"  \n",
    "   \n",
    "    final = rank_topn_per_category(candidates_by_cat, fusion_json, model_path, top_n=3)\n",
    "    print(json.dumps(final, ensure_ascii=False, indent=2))\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
